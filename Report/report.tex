\documentclass[10pt]{article}
\input{header}
\input{defs}

\usepackage{tikz}

\title{\todo\\\vspace{0.5em}\large{STAT 548 Qualifying Paper}}
\author{Kenny Chiu}
\date{\today}

\bibliography{refs.bib}

\begin{document}

\maketitle

\vspace{2em}

\begin{abstract}
\todo
\end{abstract}

\vspace{2em}


\section{Introduction}


\section{Notation}

Throughout this report, we closely follow the notation used by \textcite{Forastiere:2021}. Let $G=(\calN,\calE)$ be an undirected network where $\calN$ is a set of $N$ units (nodes) and $\calE$ is a set of edges $(i,j)$. A partition~$(i,\Ni,\Nmi)$ of $\calN$ describes unit~$i$'s neighbourhood~$\calN_i$ (the set of $N_i$ units connected to unit $i$) and the set~$\calN_{-i}$ of all other units that are not $i$ and are not in $\calN_i$. Let $Z_i\in\{0,1\}$ be the treatment assigned to unit $i$ and $Y_i\in\calY$ the observed outcome of unit $i$. Denote the treatment and outcome vector for the population~$\calN$ as $\bfZ$ and $\bfY$, respectively, and the corresponding vectors for partition~$(i,\Ni,\Nmi)$ as $(Z_i,\ZNi,\ZNmi)$ and $(Y_i,\YNi,\YNmi)$. Let $G_i=g_i(\ZNi)\in\calG_i$ be some known and well-specified summary~$g_i$ of the treatments in unit~$i$'s neighbourhood, and denote the vector of neighbourhood treatments for the population as $\bfG$. Depending on the size of a unit's neighbourhood, the space $\calG_i$ may differ between units. Let $V_g=\{i\in\calN:g\in\calG_i\}$ denote the subset containing $v_g$ units that have $g$ as a possible value for the neighbourhood treatment. Let $\bfX_i\in\calX$ be a vector of covariates for unit~$i$ that partitions into individual-level characteristics $\Xind_i\in\calX^\text{ind}$ and neighbourhood-level/aggregated individual-level characteristics $\Xneigh_i\in\calX^\text{neigh}$.


\section{Proposed methodology in context of the literature}

\todo In this section, we explain the method proposed by \textcite{Forastiere:2021} and discuss its relevance in the context of the related literature. We also discuss its advantages over other methods used in similar contexts.

\subsection{Setting, objective and method}\label{sec:method}

\textcite{Forastiere:2021} examine the problem of performing causal inference of treatment effects from observational network data under interference. The setting is challenging for causal inference because
\begin{enumerate}
\item
the assignment mechanism of treatments is unknown with observational data and so estimated effects may be non-causal in the presence of unmeasured confounders, and
\item
naive inference methods that ignore interference may produce biased estimates.
\end{enumerate}
In the randomized study literature, these issues can generally be dealt with by designing the study in such a way that the influence of confounders is minimized and that inference methods that account for interference can be used \parencite[e.g.,][]{Saveski:2017,Jagadeesan:2020,Imai:2021,Doudchenko:2020}. In the observational setting, these considerations need to be addressed by the inference method in the analysis phase. \citeauthor{Forastiere:2021} consider a setting involving a binary treatment (e.g., intervention and control) and where the interference on a unit is limited to that of its immediate neighbouring units. They propose a method to estimate the causal treatment and spillover (interference) effects that yield unbiased estimates under certain assumptions.
\\

Under the potential outcome framework, the general procedure for estimating effects is to match units into sets based on covariate values, compute the effect contrast within each matched set, and estimate the effect by the (weighted) average of the contrasts across sets. However, matching may be difficult when the space of possible covariate values is large or if there are many covariates. \textcite{Forastiere:2021} address this problem in their proposed method by instead matching on a defined joint propensity score~$\psi(z;g;x)$ that factorizes into a neighbourhood propensity score~$\lambda(g;z;\bfx^g)$ (probability of being exposed to neighbourhood treatment $g$ given individual treatment $z$ and relevant covariates $\bfx^g$) and an individual propensity score~$\phi(z;\bfx^z)$ (probability of being assigned treatment $z$ given relevant covariates $\bfx^z$). Note that $\bfX^g$ and $\bfX^z$ do not necessarily correspond to $\Xneigh$ and $\Xind$, respectively, and as they may not be disjoint. The steps for their propensity-based method are as follows:
\begin{enumerate}

\item
\textbf{Subclassify units}.
\begin{enumerate}
\item
Fit a logistic regression model on the individual treatments~$Z_i$ given covariates~$\bfX_i^z$, and use the model to predict the individual propensity scores~$\phi(1;\bfX_i^z)$.
\item
Partition the units into $J$ subclasses $B_j$, $j\in\{1,\ldots,J\}$, based on similar estimated individual propensity scores~$\hat{\phi}(1;\bfX_i^z)$ and such that each subclass is approximately balanced in the number of treated and untreated units.
\end{enumerate}

\item
\textbf{Estimate potential outcomes}. Let $B_j^g=	V_g\cap B_j$. For each subclass~$B_j$:
\begin{enumerate}
\item
Fit some regression model on the neighbourhood treatments $G_i$ given the individual treatments~$Z_i$ and covariates~$\bfX_i^g$, and use the model to estimate the neighbourhood propensity scores~$\lambda(g;z;\bfX_i^g)$.
\item
Fit some regression model on the potential outcomes~$Y_i(z,g)$ given the individual and neighbourhood treatments~$Z_i$ and $G_i$ and the estimated neighbourhood propensity scores~$\hat{\lambda}(g;z;\bfX_i^g)$.
\item
Estimate the dose-response function by averaging over the estimated potential outcomes for a particular level of the joint treatment, i.e.,
\[
\hat{\mu}_j(z,g;V_g) = \frac{\sum_{i\in B_j^g}\hat{Y}_i(z,g)}{\left|B_j^g\right|}\;.
\]
\end{enumerate}

\item
\textbf{Estimate the average dose-response function} (ADRF) $\mu(z,g;V_g)=\E\left[Y_i(z,g)|i\in V_g\right]$ for a particular level of the joint treatment by taking the weighted average of the estimated dose-response functions over the subclasses, i.e.,
\[
\hat{\mu}(z,g;V_g) = \sum_{j=1}^J\hat{\mu}_j(z,g;V_g)\left(\frac{\left|B_j^g\right|}{v_g}\right) \;.
\]

\item
\textbf{Estimate} the treatment effects $\tau(g)$, overall treatment effect $\tau$, spillover effects $\delta(g;z)$, and overall spillover effects $\Delta(z)$ by
\begin{align*}
\hat{\tau}(g) &= \hat{\mu}(1,g;V_g) - \hat{\mu}(0,g;V_g) \;, & \hat{\tau}&=\sum_{g\in\calG}\hat{\tau}(g)\P(G_i=g) \;, \\
\hat{\delta}(g;z) &= \hat{\mu}(z,g;V_g) - \hat{\mu}(z,0;V_g) \;, & \hat{\Delta}(z) &= \sum_{g\in\calG}\hat{\delta}(g;z)\P(G_i=g)\;.
\end{align*}

\end{enumerate}
\textcite{Forastiere:2021} show that their estimators for the treatment and spillover effects are unbiased under three assumptions, the first two of which form the Stable Unit Treatment on Neighbourhood Value Assumption (SUTNVA, a generalization of SUTVA that relaxes the no interference assumption to allow interference of immediate neighbours) and the third being an unconfoundedness assumption that says the treatment assignment mechanism is conditionally independent of the outcomes for the given set of covariates.

\subsection{Comparison to the literature}

The literature that examines the similar problem of causal inference in observational data under general forms of interference is still relatively new. We summarize the common approaches in this literature and discuss how the work by \textcite{Forastiere:2021} fits in. We also briefly highlight other work in the related literature.

\subsubsection{Other approaches under the same context}

As noted by \citeauthor{Forastiere:2021}, the majority of the works dealing with the same context involve either inverse probability-weighted (IPW) estimators \parencite{Liu:2016} or targeted maximum likelihood estimators (TMLE) \parencite{VanDerLaan:2014,Sofrygin:2017,Ogburn:2017} for the causal treatment effect. The main advantage of the method proposed by \textcite{Forastiere:2021} over these two approaches is the weaker assumptions that it requires.
\\

IPW estimators are weighted averages of the outcomes where the weights are defined with respect to a hypothetical allocation strategy (an assumed distribution over the neighbouring treatments) and a known or correctly modelled generalized propensity score. The Bernoulli allocation strategy \parencite{Tchetgen:2012} is commonly used, which assumes that each unit in the neighbourhood is treated independently with probability $\alpha$ and that a unit's assignment is independent of its neighbours' assignment. This assumption rules out homophily---the tendency for units with similar characteristics to form ties---which is generally a strong and unrealistic assumption to make \parencite{Shalizi:2011}. In contrast, the estimators proposed by \textcite{Forastiere:2021} only use the observed neighbourhood treatments, and therefore no assumptions that explicitly rule out homophily are made (though the issue may still manifest as an unmeasured confounder if the unconfoundedness assumption does not hold for the given set of covariates). Both the IPW estimators and the estimators proposed by \textcite{Forastiere:2021} rely on being able to correctly model the joint propensity score.
\\

TMLEs are obtained by maximizing the likelihood of the outcomes defined on a structural equation model. Similar to the IPW estimators, TMLE typically involves a randomization assumption \parencite{VanDerLaan:2014} on the model where the conditional joint distribution of the treatment assignments factorizes into independent conditionals given the covariates for all units, and similarly for the conditional joint distribution of the outcomes given the covariates and the treatment assignments. In comparison, the unconfoundedness assumption in the method proposed by \textcite{Forastiere:2021} makes a weaker assumption where the outcome and treatment assignment of each unit is conditionally independent given only the covariates of that unit. The significance of these assumptions again circle back to the argument of disregarding homophily and/or other venues of confounding. It is notable that extensions of TMLE that allow for limited forms of homophily were later introduced \parencite{Ogburn:2017}.
\\

More recently, approaches that can be described as extensions of \textcite{Forastiere:2021}'s method have been proposed. \textcite{Jackson:2020} proposed estimators based on propensity score matching but which also explicitly account for homophily by modeling neighbourhood treatment assignments as an incomplete information game. \textcite{Sanchez:2021} questioned the justification of the unconfoundedness assumption with respect to the constructed propensity score (which may be high-dimensional and challenging to estimate accurately), and proposed a two-step method where a defined network propensity score is first estimated and then used as inverse weights to match units.

\subsubsection{Other contexts}

We briefly highlight other works in the literature that consider a slightly different setting of the causal inference problem in observational data under interference. The difference in settings makes it difficult to directly compare the proposed approaches to that of \textcite{Forastiere:2021}.
\\

A large body of the literature examine the inference problem under the assumption of partial interference where units are partitioned into groups with no spillover effects between groups. The focus on partial interference settings seems to be primarily due to momentum of earlier works \parencite[e.g.,][]{Sobel:2006,Hudgens:2008} that looked at causal inference in randomized studies with interference, in which group-randomization tends to be more practical. Examples of recent work that assume partial interference include the work by \textcite{Liu:2019}, \textcite{Barkley:2020}, and \textcite{Qu:2021}. IPW estimators are commonly used in the partial interference setting as they were originally introduced for grouped observational data \parencite{Tchetgen:2012}.
\\

A small number of works consider more specific and niche contexts. For example, \textcite{Toulis:2018} explore the problem of treatment entanglement (where treatment assignments are assumed to satisfy certain restrictions) and proposes a propensity score-based estimator. \textcite{Zigler:2021} focus on the problem of bipartite causal inference with interference (where the treatment is applied to one unit and the outcome is measured on another) and proposes a IPW estimator.
%Outside of the observational setting, there are many works that study causal inference in randomized studies with potential interference. These works generally examine study designs that allow for treatment effect estimation in the presence of interference under varying contexts \parencite[e.g.,][]{Saveski:2017,Jagadeesan:2020,Imai:2021,Doudchenko:2020}


\section{Potential bias of naive estimator when unconfoundedness holds}\label{sec:example}

In this section, we describe a simple example that illustrates the relevance of Theorem~2.A, Corollary~2 and Corollary~3 in the paper by \textcite{Forastiere:2021}. Specifically, we show how for a simple network under certain assumptions, an unbiased naive estimator for the treatment effect that assumes SUTVA will be biased with the bias depending on the treatment assignment mechanism and the presence of unmeasured confounders.
% may be biased depending on the exact treatment assignment mechanism.
\\

Consider some undirected network $G=(\calN,\calE)$ where every unit is paired (has an edge) with exactly one other unit. For simplicity, we index a unit by $i\in\bbN$ for the pair and $j\in\{1,2\}$ for the unit within a pair. Denote $Z_{ij}\in\{0,1\}$ as the treatment assignment of unit $j$ in pair $i$. Let the neighbourhood treatment~$G_{ij}$ be whether a unit's paired counterpart is treated. Therefore, $\calG_{ij}=\{0,1\}$ for all units in the network and $V_g=\calN$ for all $g\in\{0,1\}$. For convenience of notation, we drop the dependence on $V_g$ where applicable. Let $\bfX_{ij}=X_{ij}\in\{0,1\}$ be some covariate available for each unit, and assume that the covariates of the units in the network are generated independently with $\P(X_{ij}=1)=\P(X_{ij}=0)=\frac{1}{2}$. Let $Y_{ij}\in\bbR$ be the outcome measured for each unit. Other details, such as the size of $\calN$, are assumed but left unspecified due to being irrelevant for the discussion. Figure~\ref{fig:example} shows an example network.
\\

\begin{figure}[ht]
\centering
\begin{tikzpicture}[thick,main/.style={draw,circle},node distance={6.5em},minimum size={1cm}]
\node[main,align=center,label={[yshift=-0.25em,align=center]$X_{11}=1$\\$Y_{11}=y_{11}$}] (11) {$Z_{11}=1$\\$G_{11}=0$};
\node[main,align=center,label={[yshift=-7.75em,align=center]$X_{12}=0$\\$Y_{12}=y_{12}$}] (12) [below of=11] {$Z_{12}=0$\\$G_{12}=1$};
\draw[line width={0.5mm}] (11) -- (12);
\node[main,align=center,label={[yshift=-0.25em,align=center]$X_{21}=0$\\$Y_{21}=y_{21}$}] (21) [right of=11]{$Z_{21}=1$\\$G_{21}=1$};
\node[main,align=center,label={[yshift=-7.75em,align=center]$X_{22}=1$\\$Y_{22}=y_{22}$}] (22) [right of=12] {$Z_{22}=1$\\$G_{22}=1$};
\draw[line width={0.5mm}] (21) -- (22);
\node[] [right of=21] (d1) {\footnotesize$\bullet\bullet\bullet$};
\node[] [right of=22] (d2) {\footnotesize$\bullet\bullet\bullet$};
\node[main,align=center,label={[yshift=-0.25em,align=center]$X_{n1}=0$\\$Y_{n1}=y_{n1}$}] (n1) [right of=d1]{$Z_{n1}=0$\\$G_{n1}=0$};
\node[main,align=center,label={[yshift=-7.75em,align=center]$X_{n1}=0$\\$Y_{n2}=y_{n2}$}] (n2) [right of=d2] {$Z_{n2}=0$\\$G_{n2}=0$};
\draw[line width={0.5mm}] (n1) -- (n2);
\node[] [right of=n1] (d3) {\footnotesize$\bullet\bullet\bullet$};
\node[] [right of=n2] (d4) {\footnotesize$\bullet\bullet\bullet$};
\end{tikzpicture}
\caption{Example network of paired units with their observed individual treatment $Z_{ij}$, neighbourhood treatment $G_{ij}$, covariate $X_{ij}$, and outcome $Y_{ij}$.}
\label{fig:example}
\end{figure}

We examine the bias of a naive estimator on this network under two settings. In both settings, we assume that Assumption~1 (no multiple versions of treatment) and Assumption~2 (neighbourhood interference) of \textcite{Forastiere:2021} hold. Derivations of the quantities presented in this section can be found in Appendix~\ref{apx:example}.
% Hence, the assumptions of Corollary~2 are satisfied in the first setting, and the assumptions of Corollary~3 are satisfied in the second setting.

\iffalse
In the first setting, suppose that the treatment assignment mechanism follows
\[
\P(Z_{ij}=1|X_{ij}) = \frac{1}{4} + \frac{1}{2}X_{ij} \;,
\]
i.e., the probability of being treated is greater when a unit has a 1-value for the covariate.
%the covariate $X_{ij}$ exactly determines the treatment status of a unit, i.e., $Z_{ij} = X_{ij}$.
Because $X_{ij}$ are generated independently, it follows that $Z_{ij}$ and $G_{ij}$ are conditionally independent given $X_{ij}$ in this setting (they are independent unconditionally regardless of $X_{ij}$). An example study corresponding to this setting may be one where the paired units correspond to a pair of friends from potentially different socioeconomic backgrounds $X_{ij}$, and it is of interest to determine whether being comfortable discussing financial matters ($Z_{ij}$) has an effect on some measure of their own financial management $Y_{ij}$.
\\

In the second setting, suppose that the treatment assignment follows
\[
\P(Z_{ij}=1|X_{i1},X_{i2}) = \frac{3}{4}\mathbbm{1}\left[X_{i1}=X_{i2}\right] + \frac{1}{4}\mathbbm{1}\left[X_{i1}\neq X_{i2}\right]
\]
where $\mathbbm{1}[\argdot]$ is the indicator function. This assignment corresponds to a type of homophily situation where the units in a pair are more likely to be treated if they share the same value of the covariate. Thus, $Z_{ij}$ and $G_{ij}$ are not conditionally independent given $X_{ij}$ in this setting as the probability of a unit being treated also depends on its counterpart. An example study corresponding to this setting may be one similar to the first but involving spouses rather than friends, where spouses coming from similar backgrounds may find it easier to discuss finances (at a more intimate level).
\fi

\subsection{Setting~1: bias of naive estimator due to correlated individual and neighbourhood treatments}

In our first setting, suppose that the treatment assignment follows
\[
\P(Z_{ij}=1|X_{i1},X_{i2}) = \frac{3}{4}\mathbbm{1}\left[X_{i1}=X_{i2}\right] + \frac{1}{4}\mathbbm{1}\left[X_{i1}\neq X_{i2}\right]
\]
where $\mathbbm{1}[\argdot]$ is the indicator function, and suppose that $Y_{ij}(z,g)\sim N(c_zz+c_gg,1)$ for some constants $c_z,c_g\in\bbR$. This treatment assignment corresponds to a type of homophily situation where the units in a pair are more likely to be treated if they share the same value of the covariate. Thus, $Z_{ij}$ and $G_{ij}$ are not conditionally independent given $X_{ij}$ as the probability of a unit being treated also depends on its counterpart. On the other hand, the unconfoundedness assumption holds for the outcome~$Y_{ij}(z,g)$ given $X_{ij}$ (or any other covariates) as the outcome only depends on the observed values of the treatments $z$ and $g$. Therefore, by Corollary~2, an effect estimator that is unbiased under SUTVA will be biased in the presence of neighbourhood interference. \todo A hypothetical study that corresponds to this setting may be one where the paired units correspond to a pair of spouses with potentially different socioeconomic backgrounds $X_{ij}$, and it is of interest to determine whether being comfortable discussing financial matters~($Z_{ij}$) has an effect on some measure of their own financial management $Y_{ij}$. The homophily context arises from the assumption that spouses who come from similar backgrounds will find it easier to discuss finances (at a more intimate level).
%An example study corresponding to this setting may be one similar to the first but involving spouses rather than friends, where spouses coming from similar backgrounds may find it easier to discuss finances (at a more intimate level).
\\

%In our first setting, the covariate $X_{ij}$ alone is insufficient for the conditional independence of the individual treatment $Z_{ij}$ and neighbourhood treatment $G_{ij}$. By Corollary~2, an effect estimator that is unbiased under SUTVA will be biased due to the association between the individual and neighbourhood treatments.
%\\

%The overall treatment effect $\tau$ in this setting is the same as the one given in the first setting.
The overall treatment effect $\tau$ in this setting is given by
\[
\tau = \E\left[Y_{ij}|Z_{ij}=1,G_{ij}=g\right] - \E\left[Y_{ij}|Z_{ij}=0,G_{ij}=g\right] = c_z \;.
\]
Using Theorem~2.A, the naive estimator $\tau_{X}^\text{obs}$ that assumes SUTVA estimates the quantity
\begin{align*}
\tau_{X}^\text{obs} &= \frac{5}{8}\left(\E\left[Y_{ij}|Z_{ij}=1,G_{ij}=1\right]-\E\left[Y_{ij}|Z_{ij}=0,G_{ij}=0\right]\right) \\
&\quad + \frac{3}{8}\left(\E\left[Y_{ij}|Z_{ij}=1,G_{ij}=0\right]-\E\left[Y_{ij}|Z_{ij}=0,G_{ij}=1\right]\right) \\
&= c_z + \frac{1}{4}c_g \;.
\end{align*}
It then follows that the bias of an unbiased estimator for $\tau_{X}^\text{obs}$ is $\tau_{X}^\text{obs} - \tau = \frac{1}{4}c_g$, i.e., the bias due to interference. Therefore, an unbiased SUTVA estimator is biased for the treatment effect when the individual and neighbourhood treatments are not conditionally independent for the given set of covariates in the presence of interference.
\\

The derivation for the overall treatment effect $\tau$, the estimator $\tau_{X}^\text{obs}$ and the bias $\tau_{X}^\text{obs}-\tau$ can be found in Appendix~\ref{apx:setting1}.

\subsection{Setting~2: bias of naive estimator due to unmeasured confounders}

In our second setting,
\iffalse
suppose that the covariates are jointly generated according to the distribution
\[
\P(X_{i1}=x_1,X_{i2}=x_2) =
\begin{cases}
\frac{3}{8} & \text{for }x_1=x_2 \\
\frac{1}{8} & \text{for }x_1\neq x_2
\end{cases} \;,
\]
i.e., a homophily situation where the units are more likely to be paired with another unit that has similar characteristics. Further
\fi
suppose that the treatment assignment mechanism follows
\[
\P(Z_{ij}=1|X_{ij}) = \frac{1}{4} + \frac{1}{2}X_{ij} \;.
\]
Further suppose that there is some unmeasured confounder $U_{ij}\in\{0,1\}$ for each unit that is generated based on the individual treatment $Z_{ij}$ according to the distribution
\[
\P(U_{ij}=1|Z_{ij}) = \frac{1}{4} + \frac{1}{2}Z_{ij}\;,
\]
and suppose that $Y_{ij}(z,g)|U_{ij}\sim N(c_zz+c_uU_{ij},1)$ for some constants $c_z,c_u\in\bbR$. Because $Z_{ij}$ only depends on $X_{ij}$ in this setting, $Z_{ij}$ and $G_{ij}$ are conditionally independent given $X_{ij}$. However, because the outcome $Y_{ij}(z,g)$ now depends on $U_{ij}$, the unconfoundedness assumption no longer holds given only $X_{ij}$. Therefore, by Corollary~3, an effect estimator that is unbiased under SUTVA will be biased due to the unmeasured confounder $U_{ij}$. \todo A hypothetical study corresponding to this setting may be one where the paired units correspond to a pair of friends from potentially different socioeconomic backgrounds $X_{ij}$, and it is of interest to determine whether being comfortable discussing financial matters ($Z_{ij}$) has an effect on some measure of their own financial management $Y_{ij}$.
\\

%In our first setting, the individual treatment $Z_{ij}$ and neighbourhood treatment $G_{ij}$ are conditionally independent given $X_{ij}$. By Corollary~1, an effect estimator that is unbiased under SUTVA will still be unbiased under the assumptions of our setting.
%\\

The overall treatment effect $\tau$ in this setting is given by
\[
\tau = \frac{1}{2}\sum_{u\in\{0,1\}}\left(\E\left[Y_{ij}|Z_{ij}=1,U_{ij}=u\right] - \E\left[Y_{ij}|Z_{ij}=0,U_{ij}=u\right]\right) = c_z \;.
\]
The naive estimator $\tau_{X}^\text{obs}$ that assumes SUTVA estimates the quantity
\begin{align*}
\tau_{X}^\text{obs} &= \sum_{u\in\{0,1\}}\left(\E\left[Y_{ij}|Z_{ij}=1,U_{ij}=u\right]\P(U_{ij}=u|Z_{ij}=1) - \E\left[Y_{ij}|Z_{ij}=0,U_{ij}=u\right]\P(U_{ij}=u|Z_{ij}=0)\right) \\
&= c_z + \frac{1}{2}c_u
\end{align*}
It then follows that the bias is $\tau_{X}^\text{obs} - \tau = \frac{1}{2}c_u$, i.e., the bias due to the unmeasured covariate. Therefore, an unbiased estimator of the SUTVA estimator is biased for the treatment effect when the unconfoundedness assumption does not hold for the given set of covariates.
\\

The derivation for the overall treatment effect $\tau$, the estimator $\tau_{X}^\text{obs}$ and the bias $\tau_{X}^\text{obs}$ can be found in Appendix~\ref{apx:setting2}.

\iffalse
The overall treatment effect $\tau$ in this setting is given by
\[
\tau = \frac{1}{4}\sum_{g,x\in\{0,1\}} \left(\E\left[Y_{ij}|Z_{ij}=1,G_{ij}=g,X_{ij}=x\right] - \E\left[Y_{ij}|Z_{ij}=0,G_{ij}=g,X_{ij}=x\right]\right) \;.
\]
Using Theorem~2.A, it can be shown that the naive estimator $\tau_{X}^\text{obs}$ that assumes SUTVA estimates the same quantity
\[
\tau_{X}^\text{obs} = \frac{1}{4}\sum_{x,g\in\{0,1\}}\left(\E\left[Y_{ij}|Z_{ij}=1,X_{ij}=x,G_{ij}=g\right] - \E\left[Y_{ij}|Z_{ij}=0,X_{ij}=x,G_{ij}=g\right]\right) \;.
\]
It then follows from the above that $\tau_{X}^\text{obs}-\tau = 0$.
\fi
\iffalse
and Assumptions~1 and 3 that
\begin{align*}
&\tau_{X}^\text{obs}-\tau \\
&= \tau_{X}^\text{obs} - \frac{1}{2}\left(\mu(1,0) + \mu(1,1) - \mu(0,0) - \mu(0,1)\right) \\
&= \tau_{X}^\text{obs} - \frac{1}{2}\sum_{x\in\{0,1\}}\left(\E\left[Y_{ij}|Z_{ij}=1,X_{ij}=x,G_{ij}=0\right] + \E\left[Y_{ij}|Z_{ij}=1,X_{ij}=x,G_{ij}=1\right]\right. \\
&\quad - \left.\E\left[Y_{ij}|Z_{ij}=0,X_{ij}=x,G_{ij}=0\right] - \E\left[Y_{ij}|Z_{ij}=0,X_{ij}=x,G_{ij}=1\right]\right)\P(X_{ij}=x) \\
&= 0 \;.
\end{align*}
\fi
\iffalse
Therefore, an unbiased estimator of the naive effect estimator is also unbiased for the treatment effect when the individual and neighbourhood treatments are conditionally independent given the set of covariates.
\\
\fi


\section{Reproducing simulation study results}

In this section, we aim to reproduce the general findings of the simulation study conducted by \textcite{Forastiere:2021}. Note that the complete Add Health dataset that \citeauthor{Forastiere:2021} work with is publicly inaccessible, and so we instead work with the Twitch Social Network dataset \parencite{Rozemberczki:2021} that is comparable in size. Twitch is an American live streaming service that focuses on video game streaming. The dataset contains several networks of streamers and their mutual friendships that were collected in May~2018. We consider a hypothetical study where we are interested in understanding the effect of streamer self-promotions and advertising (the individual treatment) on the number of subscribers (users who follow a particular streamer; the outcome). It is reasonable to assume that there is interference at play where promoting one's self would inadvertently promote the streamer's network due to the site's recommendation algorithms that suggest similar streams to a viewer.
\\

We specifically work with the EN subnetwork of the Twitch dataset, which includes a sample of streamers who stream in English. The network includes 7126 streamers and 35,324 mutual friendship relationships. A total of 3169 binary features (e.g., games liked and played, location, streaming habits, etc.) are collected from each streamer. However, the individual features are unnamed. For the purposes of this study, we only consider feature \verb|224| and feature \verb|569| due to their distribution (the second and third most represented features in the dataset, respectively). We view these features as covariates representing whether a streamer plays a particular \verb|game1| and \verb|game2|. We note that one major difference between the Twitch dataset and the Add Health dataset is that the degree of each unit is limited to at most 10 in the Add Health dataset while there is no built-in limit in the Twitch dataset. More details about the Twitch network is provided in Appendix~\ref{apx:twitch}.
\\

In the following sections, we describe our efforts to translate the simulation procedure and (partial) findings of Tables~1 and 2 in the work by \textcite{Forastiere:2021} to our Twitch data. Under various individual and neighbourhood treatment generation scenarios, Table~1 compares the theoretical bias of estimators that adjust for different sets of covariates, while Table~2 compares the observed bias and RMSE of several estimators on simulated data. In our work, we focus specifically on Scenario~1 where the unconfoundedness assumption holds given the individual-level covariates.

\subsection{Treatment and outcome generation models} \label{sec:models}

To study the bias of estimators, we simulate both the treatment $Z$ (self-promotions) and the outcome $Y$ (number of subscribers) based on the individual covariates $\Xind=(X^\text{game1},X^\text{game2})$ (streams game~1 and streams game~2). Our treatment generation model is given by
\[
\text{logit}(P(Z_i=1)) = \text{logit}(\phi(1;\Xind_i)) = -3 + 3X_i^\text{game1} + 4X_i^\text{game2} \;.
\]
Because $Z_i$ is generated only based on the individual covariates $\Xind_i$, it follows that the unconfoundedness assumption holds given $\Xind_i$. For the neighbourhood treatment $G$, we consider both the proportion (following \citeauthor{Forastiere:2021}) and the sum of treated neighbours (which may make more sense in our context) in our simulations. Additional details about the simulated treatments can be found in Appendix~\ref{apx:covbal}.
\\

Our outcome generation model is given by
\begin{align*}
Y_i(z,g)|\Xind_i &\sim N\left(\mu(z,g,\Xind_i),1\right) \;, \\
\mu(z,g,\Xind_i) &= 5 + 6\mathbbm{1}[\phi(1;\Xind_i)\geq 0.7] + 10z - 3z\mathbbm{1}[\phi(1;\Xind_i)\geq0.7] + \beta g
\end{align*}
where $\beta\in\{4,6,8\}$ (or $\{0.4,0.6,0.8\}$ for sum-neighbourhood treatment) is the low, medium and high spillover effect, respectively, for proportion-neighbourhood treatment. It follows that the treatment effect $\tau(g;
\Xind)$ and overall treatment effect $\tau$ are then
\begin{align*}
\tau(g;\Xind_i) &= \mu(1,g,\Xind_i) - \mu(0,g,\Xind_i) = 10 - 3\mathbbm{1}[\phi(1;\Xind_i)\geq0.7] \;, \\
\tau &= \sum_{x\in\calX^\text{ind}}\tau(g;x)\P(\Xind=x) \;.
\end{align*}
We remind the reader about the ``super-population'' perspective \parencite{Imbens:2015} under which expectations and probabilities are interpreted as averages over a finite network of interest. Therefore, $\tau$ is computable given a network of nodes with their covariates $\Xind$.

\subsection{Theoretical bias of estimators}

We examine the bias of estimators that assume SUTVA and that adjust for differing sets of covariates. Following \textcite{Forastiere:2021}, we consider the covariate sets $\bfX_i=\{\emptyset,\Xind_i,\bfX_i^z=\Xind_i\cup\Xneigh_i\}$ where $\Xneigh_i=\left(\frac{\sum_{k\in\calN_i}\text{game1}_k}{N_i},\frac{\sum_{k\in\calN_i}\text{game2}_k}{N_i},N_i\right)$. When no covariates are adjusted ($\bfX_i=\emptyset$), Equation~(12) in Theorem~2.B. in the work by \textcite{Forastiere:2021} is used to compute the bias. For the other two covariate sets, Equation~(11) in Corollary~2 is used. Table~\ref{tab:table1} shows the computed biases for both proportion- and sum-neighbourhood treatments on one simulated dataset.
\\

\begin{table}[ht]
\centering
\begin{tabular}{@{}rrrrr@{}}
\toprule
$G$ exposure type & Interference $(\beta)$ & Bias$(\emptyset)$ & Bias$(\Xind_i)$ & Bias$(\bfX_i^z)$ \\
\midrule
\multirow{3}{*}{Proportion} & Low (4) & 2.937 & 0.057 & 0.541 \\
& Medium (6) & 3.009 & 0.085 & 0.812 \\
& High (8) & 3.080 & 0.113 & 1.083 \\[1em]
\multirow{3}{*}{Sum} & Low (0.4) & 3.440 & -0.144 & 0.736 \\
& Medium (0.6) & 3.763 & -0.217 & 1.104 \\
& High (0.8) & 4.085 & -0.289 & 1.472 \\
\bottomrule
\end{tabular}
\caption{Bias of covariate-adjusted SUTVA estimators of $\tau$ when the unconfoundedness assumption holds given $\Xind_i$ (i.e., $Z_i\condind G_i|\Xind_i$) on one simulated dataset.}
\label{tab:table1}
\end{table}

Our findings for the estimator that does not adjust for covariates and for the estimator that adjusts for the individual covariates $\Xind_i$ are consistent with what is reported in Table~1 in the work of \textcite{Forastiere:2021}. For the estimator that adjusts for both individual and neighbourhood covariates $\bfX^z_i$, we report biases that are larger than expected. Assuming that our implementation is correct, our investigation suggests that these large values are arising due to \todo. Because there is a much larger range in node degrees in the Twitch network compared to the Add Health network, there are many more values of the neighbourhood treatment to consider in the bias computation. This consideration combined with the smaller dataset size means that many combinations of covariate values appear in only one node \todo

\subsection{Observed bias and RMSE of estimators}\label{sec:observedbias}

We examine the observed bias and RMSE of two estimators of $\tau$ that assume SUTVA on simulated datasets. The naive unadjusted estimator is the simple contrast between treated and untreated units given by
\[
\tau_\text{naive} = \bar{Y}_{Z=1} - \bar{Y}_{Z=0}
\]
where $\bar{Y}_{\argdot}$ is the mean outcome across units with $\argdot$. The regression estimator $\tau_\text{reg}$ \parencite{Imbens:2015} is extracted from a fitted linear model given by
\[
\E[Y|Z_i,\Xind_i] = \beta_0 + \tau_\text{reg}Z_i + \beta_1X_i^\text{game1} + \beta_2X_i^\text{game2}
\]
where $\beta_j$ are the other parameters of the model. The observed bias for one simulated dataset is computed as the differences between estimates $\hat{\tau}_\text{naive}$ and $\hat{\tau}_\text{reg}$ and the expected value $\tau$, which is computed using the formula provided in Section~$\ref{sec:models}$. Table~\ref{tab:table2} (estimators 1--2) reports the mean computed biases and RMSE for the two estimators over 500 simulated datasets. In each simulation, the individual and neighbourhood treatments are re-generated, and the same simulated treatments are used for all estimators and interference levels (only the outcomes are re-generated between interference levels).
\\

\iffalse
\begin{table}[ht]
\centering
\begin{tabular}{@{}rrrrrr@{}}
\toprule
& & \multicolumn{2}{c}{$\tau_\text{naive}$} & \multicolumn{2}{c}{$\tau_\text{reg}$} \\
\cmidrule(r){3-4} \cmidrule(l){5-6}
$G_i$ exposure type & Interference $(\beta)$ & Bias & RMSE & Bias & RMSE \\
\midrule
\multirow{3}{*}{Proportion} & Low (4) & 2.915 & 2.916 & 0.414 & 0.418 \\
& Medium (6) & 2.958 & 2.958 & 0.411 & 0.418 \\
& High (8) & 3.004 & 3.005 & 0.411 & 0.422 \\[1em]
\multirow{3}{*}{Sum} & Low (0.4) & 3.553 & 3.556 & 0.448 & 0.504 \\
& Medium (0.6) & 3.915 & 3.921 & 0.462 & 0.579 \\
& High (0.8) & 4.280 & 4.289 & 0.479 & 0.664 \\
\bottomrule
\end{tabular}
\caption{Mean bias and RMSE of estimators of $\tau$ when the unconfoundedness assumption holds given $\Xind_i$ (i.e., $Z_i\condind G_i|\Xind_i$) over 500 simulated datasets.}
\label{tab:table2}
\end{table}
\fi

\begin{table}[ht]
\centering
{\footnotesize
\begin{tabular}{@{}rrrrrrrrrrrrr@{}}
\toprule
& & & \multicolumn{2}{c}{$\tau_\text{reg}$} & \multicolumn{2}{c}{$\tau_\text{reg}$} & \multicolumn{2}{c}{$\tau_\text{sub}$} & \multicolumn{2}{c}{$\tau_\text{sub}$}  \\
Interference & \multicolumn{2}{c}{$\tau_\text{naive}$} & \multicolumn{2}{c}{$\sim Z_i,\Xind_i$} & \multicolumn{2}{c}{$\sim Z_i,\bfX^z_i$} & \multicolumn{2}{c}{$\hat{\phi}(1;\Xind_i)$} & \multicolumn{2}{c}{$\hat{\phi}(1;\bfX^z_i)$} & \multicolumn{2}{c}{$\tau_\text{GPS}$} \\
\cmidrule(lr){2-3} \cmidrule(lr){4-5} \cmidrule(lr){6-7} \cmidrule(lr){8-9} \cmidrule(lr){10-11} \cmidrule(lr){12-13}
\multicolumn{1}{c}{$(\beta)$} & Bias & RMSE & Bias & RMSE & Bias & RMSE & Bias & RMSE & Bias & RMSE & Bias & RMSE \\
\midrule
\multicolumn{13}{l}{Proportion $G_i$} \\[0.5em]
Low (4) & 2.915 & 2.916 & 0.414 & 0.418 & 0.417 & 0.420 & 0.036 & 0.158 & 0.002 & 0.085 & 0.003 & 0.055 \\
Med (6) & 2.958 & 2.958 & 0.411 & 0.418 & 0.416 & 0.420 & 0.033 & 0.169 & -0.001 & 0.112 & 0.000 & 0.059 \\
High (8) & 3.004 & 3.005 & 0.411 & 0.422 & 0.417 & 0.424 & 0.036 & 0.194 & 0.002 & 0.144 & 0.003 & 0.054 \\[1em]
\multicolumn{13}{l}{Sum $G_i$} \\[0.5em]
Low (0.4) & 3.553 & 3.556 & 0.448 & 0.504 & 0.406 & 0.409 & 0.021 & 0.304 & -0.310 & 0.584 & -0.064 & 0.089 \\
Med (0.6) & 3.915 & 3.921 & 0.462 & 0.579 & 0.400 & 0.404 & 0.010 & 0.431 & -0.469 & 0.877 & -0.066 & 0.093 \\
High (0.8) & 4.280 & 4.289 & 0.479 & 0.664 & 0.395 & 0.402 & 0.006 & 0.563 & -0.623 & 1.170 & -0.062 & 0.088 \\
\bottomrule
\end{tabular}
}
\caption{Mean bias and RMSE of estimators of $\tau$ when the unconfoundedness assumption holds given $\Xind_i$ (i.e., $Z_i\condind G_i|\Xind_i$) over 500 simulated datasets.}
\label{tab:table2}
\end{table}

Our findings are generally consistent with the results of \textcite{Forastiere:2021} reported in Table~2 (Unadjusted and Regression $\sim Z_i,\Xind_i$ estimators under Scenario~1) where a greater interference effect leads to a greater RMSE. The bias of the regression estimator is smaller than that of the unadjusted estimator but is still non-trivial, and is presumably due to the misspecification of the linear model.



\section{Extending the simulation study}

In this section, we extend our simulation study from Section~\ref{sec:observedbias} to the other estimators considered in Table~2 of the work by \textcite{Forastiere:2021}. These estimators include
\begin{enumerate}

\item
a second regression estimator $\tau_\text{reg}(Z_i,\bfX_i^z)$ that is adjusted for all covariates rather than only the individual covariates, i.e.,
\[
\E[Y|Z_i,\bfX_i^z] = \beta_0 + \tau_\text{reg}Z_i + \beta_1X_i^\text{game1} + \beta_2X_i^\text{game2} + \beta_3X_i^\text{Ngame1} + \beta_4X_i^\text{Ngame2} + \beta_5N_i
\]
where \verb|Ngame1| and \verb|Ngame2| are the neighbourhood proportion covariates in $\Xneigh_i$;

\item
an estimator $\tau_\text{sub}(\Xind_i)$ based on taking averages within subclasses \parencite{Imbens:2015}, which are defined based on a propensity score that adjusts for individual covariates. The procedure to compute the estimate is as follows:
\begin{enumerate}
\item
Fit a logistic regression model on the individual treatment $Z_i$ with covariates $\Xind_i$.
\item
Estimate an individual propensity score $\hat{\phi}(1;\Xind_i)$ for each unit.
\item
Partition the units into $J$ roughly equal-sized subclasses based on $\hat{\phi}(1;\Xind_i)$. In our context, $J=4$ is the maximum number of subclasses possible given the two binary covariates. We take $J=4$ in our simulations.
\item
Let $\bar{Y}^{(j)}$ denote an average computed over subclass $B_j$. Compute the estimate given by
\[
\tau_\text{sub} = \frac{1}{N}\sum_{j=1}^J\left(\bar{Y}_{Z=1}^{(j)}-\bar{Y}_{Z=0}^{(j)}\right)|B_j| \;;
\]
\end{enumerate}

\item
a second subclassification estimator $\tau_\text{sub}(\bfX^z_i)$ where the subclasses are defined based on a propensity score that adjusts for all covariates. The estimation procedure is the same as the first subclassification estimator, except that $\bfX^z_i$ is used instead of $\Xind_i$ and that we take $J=5$ in our simulations following the recommendations of \textcite{Rosenbaum:1984}; and

\item
the estimator $\tau_\text{GPS}$ proposed by \textcite{Forastiere:2021} with the estimation procedure outline in Section~\ref{sec:method}. For proportion neighbourhood treatments, logistic regression models are used for both the individual and neighbourhood propensity scores (the latter in which $N_i$ are used as weights). For sum neighbourhood treatments, a negative binomial model is used to estimate the neighbourhood propensity scores\footnote{In some instances, a particular subclass would end up with very few units and the model would fail to be fit. The units in this subclass would generally be the ones with the largest degrees in the network. In these cases, we took the estimated neighbourhood propensity scores to be 0.}. We again take $J=5$ for the number of subclasses.

\end{enumerate}
Note that where applicable, we take $V_g=\calN$ in the case of proportion neighbourhood treatment for convenience of computation. Table~\ref{tab:table2} (estimators 3--6) shows the bias and RMSE of the above estimators. In the case of proportion neighbourhood treatments, our obtained biases and RMSEs are consistent with that reported by \textcite{Forastiere:2021}. The regression estimators have relatively larger biases and RMSE due to misspecification. The subclassification estimators based on individual propensity scores have smaller biases that are comparable to the analytical bias of an unbiased SUTVA estimator that adjusts for $\Xind_i$ reported in Table~\ref{tab:table1}. The estimator proposed by \citeauthor{Forastiere:2021} based on individual and neighbourhood propensity scores achieves the smallest RMSE compared to the other estimators that ignore the effect of interference.
\\

In the case of sum neighbourhood treatments, the results are similar to the proportion case except for the subclassification estimators based on individual propensity scores. The RMSE of these estimators are relatively larger compared to the other estimators in this case. It is also worth noting that the estimator proposed by \citeauthor{Forastiere:2021} still achieves the smallest RMSE out of all the compared estimators.
\\

\todo: investigate why; effect of $J$?



\section{Critical appraisal and concluding remarks}

We conclude this report with a critical appraisal of the paper and proposed method by \textcite{Forastiere:2021}. The main contributions of the paper include a potential outcome formulation of the causal interference problem and a propensity score-based estimator for observational data that adjusts for possible interference. The formulation is useful as it provides a framework under which properties (e.g., bias) of estimators that ignore interference can be derived and quantified. Based on our simulation study, the proposed estimator appears to fulfill its purpose in being able to adjust for interference effects (when assumptions hold) as evident by the results in Table~\ref{tab:table2}. We note that the results were obtained with minimal tuning of our logistic and negative binomial models (due to the nature of the simulation study), and so we expect that this estimator would perform even better in practice with proper diagnostics and tuning of model fit.
\\

One practical consideration that seems to be missing in the paper by \textcite{Forastiere:2021} is the computational performance of the procedure to compute the estimator. The complexity notably scales with both the number of units and the number of distinct values of the neighbourhood treatment in the network. For the Add Health dataset that \citeauthor{Forastiere:2021} worked with, the latter was less of an issue as every unit was limited to having at most ten neighbours. For the Twitch dataset considered in this report, units could have many neighbours and so the number of distinct neighbourhood treatments was not trivial. With such datasets, it may be reasonable to expect that the max degree in the network scales with the total number of units, and so the computational complexity of the procedure is overall closer to quadratic in the number of units in the network. For large networks with millions of units, the procedure would likely be infeasible without further modifications.
\\

As discussed by \textcite{Forastiere:2021}, other limitations of their proposed method include its reliance on fully knowing the network structure and assuming it is fixed, and its dependence on models for the propensity scores that are likely to be misspecified. \textcite{Sanchez:2021} also questions the unconfoundedness assumption with respect to the propensity score. In practice, the unconfoundedness assumption holding with respect to a set of covariates may already be challenging to verify. Further assuming that unconfoundedness holds with respect to a (factorized) propensity score constructed on top of that set of covariates adds another layer of assumption that is difficult to justify.
\\

\todo: inconsistent results in simulation study?


\newpage


\begin{refcontext}[sorting=nyt]
\printbibliography
\end{refcontext}


\newpage

\appendix



\section{Derivations of effects, estimators and biases in example network}\label{apx:example}

This appendix section contains derivations of the overall treatment effects, estimators and their biases discussed in Section~\ref{sec:example}.

\subsection{Setting~1} \label{apx:setting1}

In Setting~1, the overall treatment effect $\tau$ is given by
\begin{align*}
%\tau(0) &= \mu(1,0) - \mu(0,0) \;, \\
%\tau(1) &= \mu(1,1) - \mu(0,1) \;, \\
\tau %&= \sum_{g\in\{0,1\}} \tau(g)\P(G_{ij}=g) \\
%&= \sum_{g\in\{0,1\}} \left(\E\left[Y_{ij}(1,g)\right] - \E\left[Y_{ij}(0,g)\right]\right)\P(G_{ij}=g) \\
&= \sum_{x\in\{0,1\}} \left(\E\left[Y_{ij}|Z_{ij}=1,G_{ij}=g,X_{ij}=x\right] - \E\left[Y_{ij}|Z_{ij}=0,G_{ij}=g,X_{ij}=x\right]\right)\P(X_{ij}=x) \\
&= \left(\E\left[Y_{ij}|Z_{ij}=1,G_{ij}=g\right] - \E\left[Y_{ij}|Z_{ij}=0,G_{ij}=g\right]\right)\sum_{x\in\{0,1\}}\P(X_{ij}=x) \\
&= \E\left[Y_{ij}|Z_{ij}=1,G_{ij}=g\right] - \E\left[Y_{ij}|Z_{ij}=0,G_{ij}=g\right] \\
&= c_z
%&= \tau(0)\P(G_{ij}=0) + \tau(1)\P(G_{ij}=1) \\
%&= \frac{1}{2}\left(\mu(1,0) + \mu(1,1) - \mu(0,0) - \mu(0,1)\right) \;.
\end{align*}
where the first equality follows from Theorem~1 and the second equality follows from the model assumptions.
\\

The naive estimator $\tau_{X}^\text{obs}$ that assumes SUTVA is given by
\begin{align*}
\tau_{X}^\text{obs} &= \sum_{x,g\in\{0,1\}}\left(\E\left[Y_{ij}|Z_{ij}=1,X_{ij}=x,G_{ij}=g\right]\P(G_{ij}=g|Z_{ij}=1,X_{ij}=x)\right. \\
&\quad - \left.\E\left[Y_{ij}|Z_{ij}=0,X_{ij}=x,G_{ij}=g\right]\P(G_{ij}=g|Z_{ij}=0,X_{ij}=x)\right)\P(X_{ij}=x) \\
&= \sum_{x,g\in\{0,1\}}\left(\E\left[Y_{ij}|Z_{ij}=1,G_{ij}=g\right]\P(G_{ij}=g|Z_{ij}=1,X_{ij}=x)\right. \\
&\quad - \left.\E\left[Y_{ij}|Z_{ij}=0,G_{ij}=g\right]\P(G_{ij}=g|Z_{ij}=0,X_{ij}=x)\right)\P(X_{ij}=x) \\
&= \sum_{x,g\in\{0,1\}}\left(\E\left[Y_{ij}|Z_{ij}=1,G_{ij}=g\right]\sum_{x'\in\{0,1\}}\P(G_{ij}=g|X_{ij}=x,X_{ik}=x')\P(X_{ik}=x'|Z_{ij}=1,X_{ij}=x)\right. \\
&\quad - \left.\E\left[Y_{ij}|Z_{ij}=0,G_{ij}=g\right]\sum_{x'\in\{0,1\}}\P(G_{ij}=g|X_{ij}=x,X_{ik}=x')\P(X_{ik}=x'|Z_{ij}=0,X_{ij}=x)\right)\P(X_{ij}=x) \\
&= \sum_{g\in\{0,1\}}\left(\E\left[Y_{ij}|Z_{ij}=1,G_{ij}=g\right]\sum_{x,x'\in\{0,1\}}\P(G_{ij}=g|X_{ij}=x,X_{ik}=x')\P(Z_{ij}=1|X_{ij}=x,X_{ik}=x')\P(X_{ij}=x)\right. \\
&\quad - \left.\E\left[Y_{ij}|Z_{ij}=0,G_{ij}=g\right]\sum_{x,x'\in\{0,1\}}\P(G_{ij}=g|X_{ij}=x,X_{ik}=x')\P(Z_{ij}=0|X_{ij}=x,X_{ik}=x')\P(X_{ij}=x)\right) \\
&= \frac{1}{2}\left(\left(2\left(\frac{3}{4}\right)^2+2\left(\frac{1}{4}\right)^2\right)\left(\E\left[Y_{ij}|Z_{ij}=1,G_{ij}=1\right]-\E\left[Y_{ij}|Z_{ij}=0,G_{ij}=0\right]\right)\right. \\
&\quad + \left.4\left(\frac{1}{4}\right)\left(\frac{3}{4}\right)\left(\E\left[Y_{ij}|Z_{ij}=1,G_{ij}=0\right]-\E\left[Y_{ij}|Z_{ij}=0,G_{ij}=1\right]\right)\right) \\
&= \frac{5}{8}\left(\E\left[Y_{ij}|Z_{ij}=1,G_{ij}=1\right]-\E\left[Y_{ij}|Z_{ij}=0,G_{ij}=0\right]\right) + \frac{3}{8}\left(\E\left[Y_{ij}|Z_{ij}=1,G_{ij}=0\right]-\E\left[Y_{ij}|Z_{ij}=0,G_{ij}=1\right]\right) \\
&= \frac{5}{8}(c_z+c_g) + \frac{3}{8}(c_z-c_g) \\
&= c_z + \frac{1}{4}c_g
\end{align*}
where the first equality follows from Theorem~2.A and the unconfoundedness assumption, the second follows from model assumptions, and the third from iterated conditioning on the counterpart unit $X_{ik}$ of $X_{ij}$, $j\neq k$, and the fact that $Z_{ij}\condind G_{ij}|X_{i1},X_{i2}$.  The fourth equality follows from Bayes' theorem manipulation where
\begin{align*}
\P(X_{ik}=x'|Z_{ij}=1,X_{ij}=x) &= \frac{\P(Z_{ij}=1|X_{ij}=x,X_{ik}=x')\P(X_{ik}=x')}{\P(Z_{ij}=1|X_{ij}=x)} \\
&= \frac{\P(Z_{ij}=1|X_{ij}=x,X_{ik}=x')\P(X_{ik}=x')}{\P(Z_{ij}=1|X_{ij}=X_{ik})P(X_{ik}=x) + \P(Z_{ij}=1|X_{ij}\neq X_{ik})P(X_{ik}=x')} \\
&= \left(\frac{\frac{1}{2}}{\left(\frac{3}{4}\right)\left(\frac{1}{2}\right)+\left(\frac{1}{4}\right)\left(\frac{1}{2}\right)}\right)\P(Z_{ij}=1|X_{ij}=x,X_{ik}=x') \\
&= \P(Z_{ij}=1|X_{ij}=x,X_{ik}=x')
\end{align*}
with the first equality following from Bayes' theorem and the assumption that $X_{i1}\condind X_{i2}$.
\\

The bias of the naive estimator can be verified using Equation~11 from Corollary~2 in the work by \textcite{Forastiere:2021}, which gives
\begin{align*}
\tau_{X}^\text{obs} - \tau &= \sum_{x\in\{0,1\}}\left(\E\left[Y_{ij}|Z_{ij}=z,G_{ij}=1,X_{ij}=x\right]-\E\left[Y_{ij}|Z_{ij}=z,G_{ij}=0,X_{ij}=x\right]\right) \\
&\quad \times\left(\P(G_{ij}=1|Z_{ij}=1,X_{ij}=x)-\P(G_{ij}=1|Z_{ij}=0,X_{ij}=x)\right)\P(X_{ij}=x) \\
&= \left(\E\left[Y_{ij}|Z_{ij}=z,G_{ij}=1\right]-\E\left[Y_{ij}|Z_{ij}=z,G_{ij}=0\right]\right) \\
&\quad \times\sum_{x,x'\in\{0,1\}}\left(\P(G_{ij}=1|X_{ij}=x,X_{ik}=x')\P(X_{ik}=x'|Z_{ij}=1,X_{ij}=x)\right. \\
&\quad - \left.\P(G_{ij}=1|X_{ij}=x,X_{ik}=x')\P(X_{ik}=x'|Z_{ij}=0,X_{ij}=x)\right)\P(X_{ij}=x) \\
&= \left(\E\left[Y_{ij}|Z_{ij}=z,G_{ij}=1\right]-\E\left[Y_{ij}|Z_{ij}=z,G_{ij}=0\right]\right) \\
&\quad \times\sum_{x,x'\in\{0,1\}}\left(\P(G_{ij}=1|X_{ij}=x,X_{ik}=x')\P(Z_{ij}=1|X_{ij}=x,X_{ik}=x')\right. \\
&\quad - \left.\P(G_{ij}=1|X_{ij}=x,X_{ik}=x')\P(Z_{ij}=0|X_{ij}=x,X_{ik}=x')\right)\P(X_{ij}=x) \\
&= \frac{1}{2}\left(2\left(\frac{3}{4}\right)^2+2\left(\frac{1}{4}\right)^2-4\left(\frac{1}{4}\right)\left(\frac{3}{4}\right)\right)\left(\E\left[Y_{ij}|Z_{ij}=z,G_{ij}=1\right]-\E\left[Y_{ij}|Z_{ij}=z,G_{ij}=0\right]\right) \\
&= \frac{1}{4}\left(\E\left[Y_{ij}|Z_{ij}=z,G_{ij}=1\right]-\E\left[Y_{ij}|Z_{ij}=z,G_{ij}=0\right]\right) \\
&= \frac{1}{4}c_g
\end{align*}
where the second equality follows from model assumptions and iterated conditioning on the counterpart unit $X_{ik}$, $j\neq k$, and the third from the above Bayes' theorem manipulation.

\iffalse
\begin{align*}
\tau_{X}^\text{obs} &= \sum_{x\in\{0,1\}}\left(\E\left[Y_{ij}|Z_{ij}=1,X_{ij}=x\right] - \E\left[Y_{ij}|Z_{ij}=0,X_{ij}=x\right]\right)\P(X_{ij}=x) \\
&= \frac{1}{2}\sum_{x,g\in\{0,1\}}\left(\E\left[Y_{ij}|Z_{ij}=1,X_{ij}=x,G_{ij}=g\right]\P(G_{ij}=g|Z_{ij}=1,X_{ij}=x)\right. \\
&\quad - \left.\E\left[Y_{ij}|Z_{ij}=0,X_{ij}=x,G_{ij}=g\right]\P(G_{ij}=g|Z_{ij}=0,X_{ij}=x)\right) \\
&= \frac{1}{2}\sum_{x,g\in\{0,1\}}\left(\E\left[Y_{ij}|Z_{ij}=1,X_{ij}=x,G_{ij}=g\right]\sum_{x'\in\{0,1\}}\P(G_{ij}=g|X_{ij}=x,X_{ik}=x')\P(X_{ik}=x'|Z_{ij}=1,X_{ij}=x)\right. \\
&\quad - \left.\E\left[Y_{ij}|Z_{ij}=0,X_{ij}=x,G_{ij}=g\right]\sum_{x'\in\{0,1\}}\P(G_{ij}=g|X_{ij}=x,X_{ik}=x')\P(X_{ik}=x'|Z_{ij}=0,X_{ij}=x)\right) \\
&= \frac{1}{2}\sum_{x,g\in\{0,1\}}\left(\E\left[Y_{ij}|Z_{ij}=1,X_{ij}=x,G_{ij}=g\right]\sum_{x'\in\{0,1\}}\P(G_{ij}=g|X_{ij}=x,X_{ik}=x')\P(Z_{ij}=1|X_{ij}=x,X_{ik}=x')\right. \\
&\quad - \left.\E\left[Y_{ij}|Z_{ij}=0,X_{ij}=x,G_{ij}=g\right]\sum_{x'\in\{0,1\}}\P(G_{ij}=g|X_{ij}=x,X_{ik}=x')\P(Z_{ij}=0|X_{ij}=x,X_{ik}=x')\right) \\
&= \frac{1}{2}\sum_{x\in\{0,1\}}\left(\left(2\left(\frac{3}{4}\right)^2+2\left(\frac{1}{4}\right)^2\right)\left(\E\left[Y_{ij}|Z_{ij}=1,X_{ij}=x,G_{ij}=1\right]-\E\left[Y_{ij}|Z_{ij}=0,X_{ij}=x,G_{ij}=0\right]\right) \right. \\
&\quad +\left. 4\cdot\frac{1}{4}\cdot\frac{3}{4}\left(\E\left[Y_{ij}|Z_{ij}=1,X_{ij}=x,G_{ij}=0\right]-\E\left[Y_{ij}|Z_{ij}=0,X_{ij}=x,G_{ij}=1\right]\right) \right) \\
&= \sum_{x\in\{0,1\}}\left(\frac{5}{8}\left(\E\left[Y_{ij}|Z_{ij}=1,X_{ij}=x,G_{ij}=1\right]-\E\left[Y_{ij}|Z_{ij}=0,X_{ij}=x,G_{ij}=0\right]\right) \right. \\
&\quad +\left. \frac{3}{8}\left(\E\left[Y_{ij}|Z_{ij}=1,X_{ij}=x,G_{ij}=0\right]-\E\left[Y_{ij}|Z_{ij}=0,X_{ij}=x,G_{ij}=1\right]\right) \right)
%&= \frac{1}{2}\left(2\left(\frac{3}{4}\right)^2+2\left(\frac{1}{4}\right)^2\right)\left(\mu(1,1) - \mu(0,0)\right) + \frac{1}{2}\cdot4\cdot\frac{1}{4}\cdot\frac{3}{4}\left(\mu(1,0) - \mu(0,1)\right) \\
%&= \frac{5}{8}\left(\mu(1,1) - \mu(0,0)\right) + \frac{3}{8}\left(\mu(1,0) - \mu(0,1)\right)
\end{align*}
where the third equality follows from the fact that $Z_{ij}\condind G_{ij}|X_{i1},X_{i2}$.

\begin{align*}
\tau_{X}^\text{obs} - \tau &= \sum_{x\in\{0,1\}} \left(\left(\E\left[Y_{ij}|Z_{ij}=1,G_{ij}=1,X_{ij}=x\right] - \E\left[Y_{ij}|Z_{ij}=1,G_{ij}=0,X_{ij}=x\right]\right)\right. \\
&\qquad \left(\P(G_{ij}=1|Z_{ij}=1,X_{ij}=x)-\P(G_{ij}=1|X_{ij}=x)\right) \\
&\quad - \left(\E\left[Y_{ij}|Z_{ij}=0,G_{ij}=1,X_{ij}=x\right] - \E\left[Y_{ij}|Z_{ij}=0,G_{ij}=0,X_{ij}=x\right]\right) \\
&\qquad \left.\left(\P(G_{ij}=1|Z_{ij}=0,X_{ij}=x)-\P(G_{ij}=1|X_{ij}=x)\right)\right)\P(X_{ij}=x) \\
&= \frac{1}{2}\sum_{x,x'\in\{0,1\}} \left(\left(\E\left[Y_{ij}|Z_{ij}=1,G_{ij}=1,X_{ij}=x\right] - \E\left[Y_{ij}|Z_{ij}=1,G_{ij}=0,X_{ij}=x\right]\right)\right. \\
&\qquad \left(\P(G_{ij}=1|X_{ij}=x,X_{ik}=x')\P(Z_{ij}=1|X_{ij}=x,X_{ik}=x')-\P(G_{ij}=1|X_{ij}=x,X_{ik}=x')\P(X_{ik}=x')\right) \\
&\quad - \left(\E\left[Y_{ij}|Z_{ij}=0,G_{ij}=1,X_{ij}=x\right] - \E\left[Y_{ij}|Z_{ij}=0,G_{ij}=0,X_{ij}=x\right]\right) \\
&\qquad \left.\left(\P(G_{ij}=1|X_{ij}=x,X_{ik}=x')\P(Z_{ij}=0|X_{ij}=x,X_{ik}=x')-\P(G_{ij}=1|X_{ij}=x,X_{ik}=x')\P(X_{ik}=x')\right)\right) \\
&= \frac{1}{2}\sum_{x\in\{0,1\}}\left(\left(2\left(\frac{3}{4}\right)^2+2\left(\frac{1}{4}\right)^2 - 1\right)\left(\E\left[Y_{ij}|Z_{ij}=1,G_{ij}=1,X_{ij}=x\right] - \E\left[Y_{ij}|Z_{ij}=1,G_{ij}=0,X_{ij}=x\right]\right)\right. \\
&\quad - \left.\left(4\cdot\frac{1}{4}\cdot\frac{3}{4} - 1\right)\left(\E\left[Y_{ij}|Z_{ij}=0,G_{ij}=1,X_{ij}=x\right] - \E\left[Y_{ij}|Z_{ij}=0,G_{ij}=0,X_{ij}=x\right]\right)\right) \\
&= \frac{1}{8}\sum_{x,z\in\{0,1\}}\left(\E\left[Y_{ij}|Z_{ij}=z,G_{ij}=1,X_{ij}=x\right] - \E\left[Y_{ij}|Z_{ij}=z,G_{ij}=0,X_{ij}=x\right]\right)
\end{align*}
where the second equality follows from the same reasoning in the derivation of $\tau_X^\text{obs}$.
\fi


\subsection{Derivation of overall treatment effect and estimator in Setting~2}\label{apx:setting2}

\todo In Setting~2, the overall treatment effect $\tau$ is given by
\begin{align*}
\tau &= \sum_{g\in\{0,1\}} \left(\E\left[Y_{ij}(1,g)\right] - \E\left[Y_{ij}(0,g)\right]\right)\P(G_{ij}=g) \\
&= \frac{1}{2}\sum_{g,x,u\in\{0,1\}} \left(\E\left[Y_{ij}|Z_{ij}=1,G_{ij}=g,X_{ij}=x,U_{ij}=u\right] - \E\left[Y_{ij}|Z_{ij}=0,G_{ij}=g,X_{ij}=x,U_{ij}=u\right]\right) \\
&\quad \times \P(U_{ij}=u|X_{ij}=x)\P(X_{ij}=x) \\
&= \frac{1}{2}\sum_{u\in\{0,1\}} \left(\E\left[Y_{ij}|Z_{ij}=1,U_{ij}=u\right] - \E\left[Y_{ij}|Z_{ij}=0,U_{ij}=u\right]\right)\sum_{x,z\in\{0,1\}}\P(U_{ij}=u|Z_{ij}=z)\P(Z_{ij}=z|X_{ij}=x) \\
&= \frac{1}{2}\left(\left(\E\left[Y_{ij}|Z_{ij}=1,U_{ij}=0\right] - \E\left[Y_{ij}|Z_{ij}=0,U_{ij}=0\right]\right)\sum_{x,z\in\{0,1\}}\P(U_{ij}=0|Z_{ij}=z)\P(Z_{ij}=z|X_{ij}=x) \right. \\
& \quad+ \left.\left(\E\left[Y_{ij}|Z_{ij}=1,U_{ij}=1\right] - \E\left[Y_{ij}|Z_{ij}=0,U_{ij}=1\right]\right)\sum_{x,z\in\{0,1\}}\P(U_{ij}=1|Z_{ij}=z)\P(Z_{ij}=z|X_{ij}=x)\right) \\
&= \frac{1}{2}\left(\E\left[Y_{ij}|Z_{ij}=1,U_{ij}=0\right] - \E\left[Y_{ij}|Z_{ij}=0,U_{ij}=0\right] + \E\left[Y_{ij}|Z_{ij}=1,U_{ij}=1\right] - \E\left[Y_{ij}|Z_{ij}=0,U_{ij}=1\right]\right) \\
&= c_z
\end{align*}
\todo where the second equality follows from independence of $X_{i1}$ and $X_{i2}$, fourth equality from marginalization. \begin{align*}
\tau_{X}^\text{obs} &= \sum_{x\in\{0,1\}}\left(\E\left[Y_{ij}|Z_{ij}=1,X_{ij}=x\right] - \E\left[Y_{ij}|Z_{ij}=0,X_{ij}=x\right]\right)\P(X_{ij}=x) \\
&= \frac{1}{2}\sum_{x,u\in\{0,1\}}\left(\E\left[Y_{ij}|Z_{ij}=1,X_{ij}=x,U_{ij}=u\right]\P(U_{ij}=u|Z_{ij}=1) - \E\left[Y_{ij}|Z_{ij}=0,X_{ij}=x,U_{ij}=u\right]\P(U_{ij}=u|Z_{ij}=0)\right) \\
&= \sum_{u\in\{0,1\}}\left(\E\left[Y_{ij}|Z_{ij}=1,U_{ij}=u\right]\P(U_{ij}=u|Z_{ij}=1) - \E\left[Y_{ij}|Z_{ij}=0,U_{ij}=u\right]\P(U_{ij}=u|Z_{ij}=0)\right) \\
&= \frac{1}{4}c_z - 0 + \cdot\frac{3}{4}(c_z+c_u) - \frac{1}{4}c_u \\
&= c_z + \frac{1}{2}c_u
\end{align*}
following the same reasoning as in the derivation for $\tau$. Corollary~3:
\begin{align*}
\tau_{X}^\text{obs} - \tau &= \sum_{x\in\{0,1\}}\left(\E\left[Y_{ij}|Z_{ij}=z,X_{ij}=x,U_{ij}=1\right]-\E\left[Y_{ij}|Z_{ij}=z,X_{ij}=x,U_{ij}=0\right]\right)\left(\P(U_{ij}=1|Z_{ij}=1,X_{ij}=x)-\P(U_{ij}=1|Z_{ij}=0,X_{ij}=x)\right)\P(X_{ij}=x) \\
&= \left(\E\left[Y_{ij}|Z_{ij}=z,U_{ij}=1\right]-\E\left[Y_{ij}|Z_{ij}=z,U_{ij}=0\right]\right)\left(\P(U_{ij}=1|Z_{ij}=1)-\P(U_{ij}=1|Z_{ij}=0)\right) \\
&= \frac{1}{2}\left(\E\left[Y_{ij}|Z_{ij}=z,U_{ij}=1\right]-\E\left[Y_{ij}|Z_{ij}=z,U_{ij}=0\right]\right) \\
&=\frac{1}{2}c_u
\end{align*}


\iffalse
\begin{align*}
\tau_{X}^\text{obs} - \tau &= \sum_{x\in\{0,1\}}\left(\E\left[Y_{ij}|Z_{ij}=1,X_{ij}=x,U_{ij}=1\right]\P(U_{ij}=1|Z_{ij}=1)-\E\left[Y_{ij}|Z_{ij}=0,X_{ij}=x,U_{ij}=1\right]\P(U_{ij}=1|Z_{ij}=0) \right. \\
&\quad + \left.\E\left[Y_{ij}|Z_{ij}=1,X_{ij}=x,U_{ij}=0\right]\P(U_{ij}=0|Z_{ij}=1)-\E\left[Y_{ij}|Z_{ij}=0,X_{ij}=x,U_{ij}=0\right]\P(U_{ij}=0|Z_{ij}=0)\right) \\
&\quad - \E\left[Y_{ij}|Z_{ij}=1,X_{ij}=x,U_{ij}=1\right]\P(U_{ij}=1|Z_{ij}=1) +\E\left[Y_{ij}|Z_{ij}=0,X_{ij}=x,U_{ij}=1\right]\P(U_{ij}=1|X_{ij}=x) \\
&\quad - \left.\E\left[Y_{ij}|Z_{ij}=1,X_{ij}=x,U_{ij}=0\right]\P(U_{ij}=0|Z_{ij}=1) +\E\left[Y_{ij}|Z_{ij}=0,X_{ij}=x,U_{ij}=0\right]\P(U_{ij}=0|X_{ij}=x)\right)\P(X_{ij}=x) \\
&= \sum_{x\in\{0,1\}}\left(\E\left[Y_{ij}|Z_{ij}=1,U_{ij}=1\right](\P(U_{ij}=1|Z_{ij}=1)-\P(U_{ij}=1|X_{ij}=x))\right. \\
&\quad -\E\left[Y_{ij}|Z_{ij}=0,U_{ij}=1\right](\P(U_{ij}=1|Z_{ij}=0)-\P(U_{ij}=1|X_{ij}=x))  \\
&\quad + \E\left[Y_{ij}|Z_{ij}=1,U_{ij}=0\right](\P(U_{ij}=0|Z_{ij}=1)-\P(U_{ij}=0|X_{ij}=x)) \\
&\quad - \left.\E\left[Y_{ij}|Z_{ij}=0,U_{ij}=0\right](\P(U_{ij}=0|Z_{ij}=0)-\P(U_{ij}=0|X_{ij}=x))\right)\P(X_{ij}=x) \\
&= \left(\E\left[Y_{ij}|Z_{ij}=1,U_{ij}=1\right](\P(U_{ij}=1|Z_{ij}=1)-\P(U_{ij}=1))\right. \\
&\quad -\E\left[Y_{ij}|Z_{ij}=0,U_{ij}=1\right](\P(U_{ij}=1|Z_{ij}=0)-\P(U_{ij}=1))  \\
&\quad + \E\left[Y_{ij}|Z_{ij}=1,U_{ij}=0\right](\P(U_{ij}=0|Z_{ij}=1)-\P(U_{ij}=0)) \\
&\quad - \left.\E\left[Y_{ij}|Z_{ij}=0,U_{ij}=0\right](\P(U_{ij}=0|Z_{ij}=0)-\P(U_{ij}=0))\right) \\
&= 9\cdot\frac{1}{4} - 6\cdot\left(-\frac{1}{4}\right) + 8\cdot\left(-\frac{1}{4}\right) - 5\cdot\frac{1}{4} \\
&= \frac{1}{2}
\end{align*}
\fi

\iffalse
\begin{align*}
%\tau(0) &= \mu(1,0) - \mu(0,0) \;, \\
%\tau(1) &= \mu(1,1) - \mu(0,1) \;, \\
\tau %&= \sum_{g\in\{0,1\}} \tau(g)\P(G_{ij}=g) \\
&= \sum_{g\in\{0,1\}} \left(\E\left[Y_{ij}(1,g)\right] - \E\left[Y_{ij}(0,g)\right]\right)\P(G_{ij}=g) \\
&= \frac{1}{2}\sum_{g,x\in\{0,1\}} \left(\E\left[Y_{ij}|Z_{ij}=1,G_{ij}=g,X_{ij}=x\right] - \E\left[Y_{ij}|Z_{ij}=0,G_{ij}=g,X_{ij}=x\right]\right)\P(X_{ij}=x) \\
&= \frac{1}{4}\sum_{g,x\in\{0,1\}} \left(\E\left[Y_{ij}|Z_{ij}=1,G_{ij}=g,X_{ij}=x\right] - \E\left[Y_{ij}|Z_{ij}=0,G_{ij}=g,X_{ij}=x\right]\right)
%&= \tau(0)\P(G_{ij}=0) + \tau(1)\P(G_{ij}=1) \\
%&= \frac{1}{2}\left(\mu(1,0) + \mu(1,1) - \mu(0,0) - \mu(0,1)\right) \;.
\end{align*}
where the second equality follows from Theorem~1 in the work by \textcite{Forastiere:2021}. The naive estimator $\tau_{X}^\text{obs}$ that assumes SUTVA is given by
\begin{align*}
\tau_{X}^\text{obs} &=
\sum_{x\in\{0,1\}}\left(\E\left[Y_{ij}|Z_{ij}=1,X_{ij}=x\right] - \E\left[Y_{ij}|Z_{ij}=0,X_{ij}=x\right]\right)\P(X_{ij}=x) \\
&= \frac{1}{2}\sum_{x,g\in\{0,1\}}\left(\E\left[Y_{ij}|Z_{ij}=1,X_{ij}=x,G_{ij}=g\right] - \E\left[Y_{ij}|Z_{ij}=0,X_{ij}=x,G_{ij}=g\right]\right)\P(G_{ij}=g) \\
&= \frac{1}{4}\sum_{x,g\in\{0,1\}}\left(\E\left[Y_{ij}|Z_{ij}=1,X_{ij}=x,G_{ij}=g\right] - \E\left[Y_{ij}|Z_{ij}=0,X_{ij}=x,G_{ij}=g\right]\right)
%&= \frac{1}{4}\sum_{x\in\{0,1\}}\left(\E\left[Y_{ij}|Z_{ij}=1,X_{ij}=x,G_{ij}=0\right] + \E\left[Y_{ij}|Z_{ij}=1,X_{ij}=x,G_{ij}=1\right]\right. \\
%&\quad - \left.\E\left[Y_{ij}|Z_{ij}=0,X_{ij}=x,G_{ij}=0\right] - \E\left[Y_{ij}|Z_{ij}=0,X_{ij}=x,G_{ij}=1\right]\right)
\end{align*}
where the second equality follows from the model assumptions where $G_{ij}\condind X_{ij}, Z_{ij}$.
\fi



\newpage



\section{Twitch dataset details}\label{apx:twitch}

\todo

Distribution of features \verb|224| and \verb|569|:

\begin{table}[H]
\centering
\begin{tabular}{@{}rrrl@{}}
\toprule
& \multicolumn{2}{c}{game2} \\
\cmidrule(lr){2-3}
game1 & 0 & 1 & Total \\
\midrule
0 & 1582 (22\%) & 1728 (24\%) & 3310 (46\%) \\
1 & 1834 (26\%) & 1982 (28\%) & 3816 (54\%) \\
Total & 3416 (48\%) & 3710 (52\%) & 7216 \\
\bottomrule
\end{tabular}
\end{table}

Distribution of degrees:
\begin{verbatim}
   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
  1.000   2.000   5.000   9.914  11.000 720.000
  
 SD = 22.19026
\end{verbatim}

\subsection{Covariate balance} \label{apx:covbal}

In one simulated dataset:

\begin{table}[H]
\centering
\begin{tabular}{@{}lrrr@{}}
\toprule
Variable & $\bar{X}_{Z=1}$ & $\bar{X}_{Z=0}$ & Standardized Diff. \\
\midrule
game1 & 0.683 & 0.326 &  \\
game2 & 0.763 & 0.176 &  \\
Neighbours' game1 & 0.486 & 0.466 & \\
Neighbours' game2 & 0.620 & 0.586 & \\
Degree & 10.757 & 8.717 & \\
Proportion $G_i$ & 0.604 & 0.569 & \\
Sum $G_i$ & 6.979 & 5.365 & \\
\bottomrule
\end{tabular}
\caption{Covariate balance across individual treatment arms.}
\end{table}

Distribution of proportion $G_i$'s:
\begin{verbatim}
   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
 0.0000  0.4444  0.6250  0.5896  0.7989  1.0000
 
 SD = 0.298948
\end{verbatim}

Distribution of sum $G_i$'s:
\begin{verbatim}
   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
  0.000   1.000   3.000   6.312   7.000 489.000 
  
 SD = 14.73202
\end{verbatim}

\begin{table}[H]
\centering
\begin{tabular}{@{}lrrrrrr@{}}
\toprule
Variable & $\bar{X}_{G\geq0.5}$ & $\bar{X}_{G<0.5}$ & Standardized Diff. & $\bar{X}_{G\geq3}$ & $\bar{X}_{G<3}$ & Standardized Diff. \\
\midrule
game1 & 0.558 & 0.471 & & 0.723 & 0.334 & \\
game2 & 0.542 & 0.461 & & 0.555 & 0.483 & \\
Neighbours' game1 & 0.553 & 0.267 & & 0.564 & 0.385 & \\
Neighbours' game2 & 0.669 & 0.430 & & 0.631 & 0.580 & \\
Degree & 11.694 & 4.897 & & 16.905 & 2.432 & \\
$Z_i$ & 0.608 & 0.526 & & 0.677 & 0.490 & \\
\bottomrule
\end{tabular}
\caption{Covariate balance across dichotomized neighbourhood treatment arms.}
\end{table}

\todo: add histogram of log $N_i$ and $G_i$?

\end{document}



The work by \textcite{Forastiere:2021} fits into the niche literature that looks at performing causal inference on observational network data in the presence of interference. \textcite{Forastiere:2021} formulate the network interference problem under the potential outcome framework (\todo cite), and propose a procedure to estimate causal treatment and spillover effects (as defined under their formulation) based on a joint propensity score that they define for network data. Their proposed propensity-adjusted estimators are unbiased under three assumptions, two of which form the Stable Unit Treatment on Neighbourhood Value Assumption (SUTNVA, a generalization of SUTVA that relaxes the no interference assumption to allow interference from directly connected nodes) and the third being an unconfoundedness assumption that says the treatment assignment mechanism is conditionally independent of the outcomes for some set of covariates. In addition, \textcite{Forastiere:2021} also derive the bias of SUTVA-assuming estimators when SUTVA does not hold or when the unconfoundedness assumption does not hold for the given set of covariates. The problem formulation, the proposed estimation procedure (based on a defined joint propensity score), and the derived bias of the naive estimator are the main contributions of \citeauthor{Forastiere:2021}.

\item
$\calN=\{1,2,3,4\}$, $\calE=\{(1,2),(3,4)\}$

\item
$\calY=\bbR$, $Z_i\in\{0,1\}$, $\calX=\{0,1\}$, $\calG_i=\{0,1\}$ for all $i$ (has treated friend), $V_g=\calN$ for all $g$

\item
If unconfoundedness assumption holds:
\begin{align*}
Y_i(z,g)|X_i &\sim N(\mu(z,g,X_i),1) \\
\mu(z,g,X_i) &= 6X_i + 3z + g
\end{align*}
Make deterministic:
\[
Y_i(z,g)|X_i = \mu(z,g,X_i) = 6X_i+3z+g
\]

\item
Corollary~1 holds:
\[
\textrm{logit}(P(Z_i=1)) = \log(0.5) + \log(4)X_i
\]
Make deterministic:

\item
Corollary~2 holds:
\[
\textrm{logit}(P(Z_i=1)) = \log(0.5) + \log(4)X_i + \log(2)\sum_{(i,j)\in\calE}X_j
\]


\item
Consider network where all units are in pairs.

$\calY=\bbR$, $Z_i\in\{0,1\}$, $\calX=\{0,1\}$, $\calG_i=\{0,1\}$ for all $i$ (has treated friend), $V_g=\calN$ for all $g$. $\P(X=1)=0.5$.

Corollary~1 setting: $Z_i=\mathbbm{1}(X_i=1)$ ($Z_i$ and $G_i$ entirely independent).

Corollary~2 setting: $Z_i=\sim X_i\otimes X_i'$ ($Z_i$ and $G_i$ not conditionally independent given $X_i$; only possible combinations are $(Z_i=1,G_i=1)$ and $(Z_i=0,G_i=0)$).

Show unbiasedness/biasedness of naive estimator (not accounting for spillover) based on averaging


\item
Setting 1:
\begin{align*}
\tau(1) &= \mu(1,1) - \mu(0,1) \\
\tau(0) &= \mu(1,0) - \mu(0,0) \\
\tau &= 0.5(\mu(1,0) + \mu(1,1) - \mu(0,0) - \mu(0,1)) \\
\end{align*}
\begin{align*}
\tau_{X^*}^\text{obs} &= 0.5(\E[Y|Z=1,X=0] - \E[Y|Z=0,X=0] + \E[Y|Z=1,X=1] - \E[Y|Z=0,X=1]) \\
&= \E[Y|Z=1] - \E[Y|Z=0] \\
&= \E[Y|Z=1,G=1]P(G=1|Z=1) + \E[Y|Z=1,G=0]P(G=0|Z=1) - \E[Y|Z=0,G=1]P(G=1|Z=0) - \E[Y|Z=0,G=0]P(G=0|Z=0) \\
&= 0.5(\E[Y|Z=1,G=1] + \E[Y|Z=1,G=0] - \E[Y|Z=0,G=1] - \E[Y|Z=0,G=0])
\end{align*}

\iffalse
\begin{align*}
\tau_{X}^\text{obs} &= \left(\E\left[Y_{ij}|Z_{ij}=1,X_{ij}=0\right] - \E\left[Y_{ij}|Z_{ij}=0,X_{ij}=0\right]\right)\P(X_{ij}=0) \\
&\quad + \left(\E\left[Y_{ij}|Z_{ij}=1,X_{ij}=1\right] - \E\left[Y_{ij}|Z_{ij}=0,X_{ij}=1\right]\right)\P(X_{ij}=1) \\
&= \E\left[Y_{ij}|Z_{ij}=1\right] - \E\left[Y_{ij}|Z_{ij}=0\right] \\
&= \left(\E\left[Y_{ij}|Z_{ij}=1,G_{ij}=0\right] - \E\left[Y_{ij}|Z_{ij}=0,G_{ij}=0\right]\right)\P(G_{ij}=0) \\
&\quad + \left(\E\left[Y_{ij}|Z_{ij}=1,G_{ij}=1\right] - \E\left[Y_{ij}|Z_{ij}=0,G_{ij}=1\right]\right)\P(G_{ij}=1) \\
&= 0.5\left(\mu(1,0) + \mu(1,1) - \mu(0,0) - \mu(0,1)\right)

&= \frac{1}{2}\left(\E\left[Y_{ij}|Z_{ij}=1,X_{ij}=0,G_{ij}=0\right]\P(G_{ij}=0) + \E\left[Y_{ij}|Z_{ij}=1,X_{ij}=0,G_{ij}=1\right]\P(G_{ij}=1)\right. \\
&\quad - \E\left[Y_{ij}|Z_{ij}=0,X_{ij}=0,G_{ij}=0\right]\P(G_{ij}=0) - \E\left[Y_{ij}|Z_{ij}=0,X_{ij}=0,G_{ij}=1\right]\P(G_{ij}=1) \\
&\quad + \E\left[Y_{ij}|Z_{ij}=1,X_{ij}=1,G_{ij}=0\right]\P(G_{ij}=0) + \E\left[Y_{ij}|Z_{ij}=1,X_{ij}=1,G_{ij}=1\right]\P(G_{ij}=1) \\
&\quad - \left.\E\left[Y_{ij}|Z_{ij}=0,X_{ij}=1,G_{ij}=0\right]\P(G_{ij}=0) - \E\left[Y_{ij}|Z_{ij}=0,X_{ij}=1,G_{ij}=1\right]\P(G_{ij}=1)\right) \\
\end{align*}
\fi

\begin{itemize}

\item
Setting 2:
\begin{align*}
\tau(1) &= \mu(1,1) \\
\tau(0) &= - \mu(0,0) \\
\tau &= 0.5(\mu(1,1) - \mu(0,0))
\end{align*}
\begin{align*}
\tau_{X^*}^\text{obs} &= 0.5(\E[Y|Z=1,X=0] - \E[Y|Z=0,X=0] + \E[Y|Z=1,X=1] - \E[Y|Z=0,X=1]) \\
&= \E[Y|Z=1] - \E[Y|Z=0] \\
&= \E[Y|Z=1,G=1]P(G=1|Z=1) + \E[Y|Z=1,G=0]P(G=0|Z=1) - \E[Y|Z=0,G=1]P(G=1|Z=0) - \E[Y|Z=0,G=0]P(G=0|Z=0) \\
&= \E[Y|Z=1,G=1] - \E[Y|Z=0,G=0]
\end{align*}
\begin{align*}
&\tau_{X^*}^\text{obs} \\
&= (\E[Y(1,1)|X=1]P(G=1|Z=1,X=1) - \E[Y(0,1)|X=1]P(G=1|Z=0,X=1))P(X=1) \\
& + (\E[Y(1,0)|X=1]P(G=0|Z=1,X=1) - \E[Y(0,0)|X=1]P(G=0|Z=0,X=1))P(X=1) \\
& + (\E[Y(1,1)|X=0]P(G=1|Z=1,X=0) - \E[Y(0,1)|X=0]P(G=1|Z=0,X=0))P(X=0) \\
& + (\E[Y(1,0)|X=0]P(G=0|Z=1,X=0) - \E[Y(0,0)|X=0]P(G=0|Z=0,X=0))P(X=0) \\
&= 0.5\E[Y(1,1)|X=1] - 0.5\E[Y(0,0)|X=1] + 0.5\E[Y(1,1)|X=0] - 0.5\E[Y(0,0)|X=0] \\
&= \E[Y(1,1)] - \E[Y(0,0)]
\end{align*}
\begin{align*}
&\tau_{X^*}^\text{obs} - \tau \\
&=(\E[Y|Z=1,G=1,X=1]-\E[Y|Z=1,G=0,X=1])(P(G=1|Z=1,X=1)-P(G=1|X=1))P(X=1) \\
&- (\E[Y|Z=0,G=1,X=1]-\E[Y|Z=0,G=0,X=1])(P(G=1|Z=0,X=1)-P(G=1|X=1))P(X=1) \\
&+ (\E[Y|Z=1,G=1,X=0]-\E[Y|Z=1,G=0,X=0])(P(G=1|Z=1,X=0)-P(G=1|X=0))P(X=0) \\
&- (\E[Y|Z=0,G=1,X=0]-\E[Y|Z=0,G=0,X=0])(P(G=1|Z=0,X=0)-P(G=1|X=0))P(X=0) \\
&= 0.25\E[Y|Z=1,G=1,X=1] - 0.25\E[Y|Z=0,G=0,X=1] + 0.25\E[Y|Z=1,G=1,X=0] - 0.25\E[Y|Z=0,G=0,X=0] \\
&= 0.5\E[Y|Z=1,G=1] - 0.5\E[Y|Z=0,G=0]
\end{align*}

\end{itemize}



\begin{align*}
\delta(g;z) &= \mu(z,g,\Xind_i) - \mu(z,0,\Xind_i) = \beta g \\
\Delta(z) &= \delta\E[G_i] \qquad \forall z\in\{0,1\} \\
\mu(z,g,u) - \mu(z,0,u') &= 6(\mathbbm{1}[\phi(1;u)\geq 0.7]-\mathbbm{1}[\phi(1;u')\geq 0.7]) - 3z(\mathbbm{1}[\phi(1;u)\geq0.7] - \mathbbm{1}[\phi(1;u')\geq0.7]) + \beta g
\end{align*}