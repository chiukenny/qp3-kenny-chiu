\documentclass[10pt]{article}
\input{header}
\input{defs}

\usepackage{tikz}

\title{\todo\\\vspace{0.5em}\large{STAT 548 Qualifying Paper}}
\author{Kenny Chiu}
\date{\today}

\bibliography{refs.bib}

\begin{document}

\maketitle

\vspace{2em}

\begin{abstract}
\todo
\end{abstract}

\vspace{2em}


\section{Introduction}


\section{Notation}

Throughout this report, we closely follow the notation used by \textcite{Forastiere:2021}. Let $G=(\calN,\calE)$ be an undirected network where $\calN$ is a set of $N$ units (nodes) and $\calE$ is a set of edges $(i,j)$. A partition~$(i,\Ni,\Nmi)$ of $\calN$ describes unit~$i$'s neighbourhood~$\calN_i$ (the set of $N_i$ units connected to unit $i$) and the set~$\calN_{-i}$ of all other units that are not $i$ and are not in $\calN_i$. Let $Z_i\in\{0,1\}$ be the treatment assigned to unit $i$ and $Y_i\in\calY$ the observed outcome of unit $i$. Denote the treatment and outcome vector for the population~$\calN$ as $\bfZ$ and $\bfY$, respectively, and the corresponding vectors for partition~$(i,\Ni,\Nmi)$ as $(Z_i,\ZNi,\ZNmi)$ and $(Y_i,\YNi,\YNmi)$. Let $G_i=g_i(\ZNi)\in\calG_i$ be some known and well-specified summary~$g_i$ of the treatments in unit~$i$'s neighbourhood, and denote the vector of neighbourhood treatments for the population as $\bfG$. Depending on the size of a unit's neighbourhood, the space $\calG_i$ may differ between units. Let $V_g=\{i\in\calN:g\in\calG_i\}$ denote the subset containing $v_g$ units that have $g$ as a possible value for the neighbourhood treatment. Let $\bfX_i\in\calX$ be a vector of covariates for unit~$i$ that partitions into individual-level characteristics $\Xind_i\in\calX^\text{ind}$ and neighbourhood-level/aggregated individidual-level characteristics $\Xneigh_i\in\calX^\text{neigh}$.


\section{Proposed methodology in context of the literature}

\todo In this section, we explain the method proposed by \textcite{Forastiere:2021} and discuss its relevance in the context of the related literature. We also discuss its advantages over other methods used in similar contexts.

\subsection{Setting, objective and method}

\textcite{Forastiere:2021} examine the problem of performing causal inference of treatment effects from observational network data under interference. The setting is challenging for causal inference because
\begin{enumerate}
\item
the assignment mechanism of treatments is unknown with observational data and so estimated effects may be non-causal in the presence of unmeasured confounders, and
\item
naive inference methods that ignore interference may produce biased estimates.
\end{enumerate}
In the randomized study literature, these issues can generally be dealt with by designing the study in such a way that the influence of confounders is minimized and that inference methods that account for interference can be used \parencite[e.g.,][]{Saveski:2017,Jagadeesan:2020,Imai:2021,Doudchenko:2020}. In the observational setting, these considerations need to be addressed by the inference method in the analysis phase. \citeauthor{Forastiere:2021} consider a setting involving a binary treatment (e.g., intervention and control) and where the interference on a unit is limited to that of its immediate neighbouring units. They propose a method to estimate the causal treatment and spillover (interference) effects that yield unbiased estimates under certain assumptions.
\\

Under the potential outcome framework, the general procedure for estimating effects is to match units into sets based on covariate values, compute the effect contrast within each matched set, and estimate the effect by the (weighted) average of the contrasts across sets. However, matching may be difficult when the space of possible covariate values is large or if there are many covariates. \textcite{Forastiere:2021} address this problem in their proposed method by instead matching on a defined joint propensity score~$\psi(z;g;x)$ that factorizes into a neighbourhood propensity score~$\lambda(g;z;\bfx^g)$ (probability of being exposed to neighbourhood treatment $g$ given individual treatment $z$ and relevant covariates $\bfx^g$) and an individual propensity score~$\phi(z;\bfx^z)$ (probability of being assigned treatment $z$ given relevant covariates $\bfx^z$). Note that $\bfX^g$ and $\bfX^z$ do not necessarily correspond to $\Xneigh$ and $\Xind$, respectively, and as they may not be disjoint. The steps for their propensity-based method are as follows:
\begin{enumerate}

\item
\textbf{Subclassify units}.
\begin{enumerate}
\item
Fit a logistic regression model on the individual treatments~$Z_i$ given covariates~$\bfX_i^z$, and use the model to predict the individual propensity scores~$\phi(1;\bfX_i^z)$.
\item
Partition the units into $J$ subclasses $B_j$, $j\in\{1,\ldots,J\}$, based on similar estimated individual propensity scores~$\hat{\phi}(1;\bfX_i^z)$ and such that each subclass is approximately balanced in the number of treated and untreated units.
\end{enumerate}

\item
\textbf{Estimate potential outcomes}. Let $B_j^g=	V_g\cap B_j$. For each subclass~$B_j$:
\begin{enumerate}
\item
Fit some regression model on the neighbourhood treatments $G_i$ given the individual treatments~$Z_i$ and covariates~$\bfX_i^g$, and use the model to predict the neighbourhood propensity scores~$\lambda(g;z;\bfX_i^g)$.
\item
Fit some regression model on the potential outcomes~$Y_i(z,g)$ given the estimated neighbourhood propensity scores~$\hat{\lambda}(g;z;\bfX_i^g)$.
\item
Estimate the dose-response function by averaging over the estimated potential outcomes for a particular level of the joint treatment, i.e.,
\[
\hat{\mu}_j(z,g;V_g) = \frac{\sum_{i\in B_j^g}\hat{Y}_i(z,g)}{\left|B_j^g\right|}\;.
\]
\end{enumerate}

\item
\textbf{Estimate the average dose-response function} (ADRF) $\mu(z,g;V_g)=\E\left[Y_i(z,g)|i\in V_g\right]$ for a particular level of the joint treatment by taking the weighted average of the estimated dose-response functions over the subclasses, i.e.,
\[
\hat{\mu}(z,g;V_g) = \sum_{j=1}^J\hat{\mu}_j(z,g;V_g)\left(\frac{\left|B_j^g\right|}{v_g}\right) \;.
\]

\item
\textbf{Estimate} the treatment effects $\tau(g)$, overall treatment effect $\tau$, spillover effects $\delta(g;z)$, and overall spillover effects $\Delta(z)$ by
\begin{align*}
\hat{\tau}(g) &= \hat{\mu}(1,g;V_g) - \hat{\mu}(0,g;V_g) \;, & \hat{\tau}&=\sum_{g\in\calG}\hat{\tau}(g)\P(G_i=g) \;, \\
\hat{\delta}(g;z) &= \hat{\mu}(z,g;V_g) - \hat{\mu}(z,0;V_g) \;, & \hat{\Delta}(z) &= \sum_{g\in\calG}\hat{\delta}(g;z)\P(G_i=g)\;.
\end{align*}

\end{enumerate}
\textcite{Forastiere:2021} show that their estimators for the treatment and spillover effects are unbiased under three assumptions, the first two of which form the Stable Unit Treatment on Neighbourhood Value Assumption (SUTNVA, a generalization of SUTVA that relaxes the no interference assumption to allow interference of immediate neighbours) and the third being an unconfoundedness assumption that says the treatment assignment mechanism is conditionally independent of the outcomes for the given set of covariates.

\subsection{Comparison to the literature}

The literature that examines the similar problem of causal inference in observational data under general forms of interference is still relatively new. We summarize the common approaches in this literature and discuss how the work by \textcite{Forastiere:2021} fits in. We also briefly highlight other work in the related literature.

\subsubsection{Other approaches under the same context}

As noted by \citeauthor{Forastiere:2021}, the majority of the works dealing with the same context involve either inverse probability-weighted (IPW) estimators \parencite{Liu:2016} or targeted maximum likelihood estimators (TMLE) \parencite{VanDerLaan:2014,Sofrygin:2017,Ogburn:2017} for the causal treatment effect. The main advantage of the method proposed by \textcite{Forastiere:2021} over these two approaches is the weaker assumptions that it requires.
\\

IPW estimators are weighted averages of the outcomes where the weights are defined with respect to a hypothetical allocation strategy (an assumed distribution over the neighbouring treatments) and a known or correctly modelled generalized propensity score. The Bernoulli allocation strategy \parencite{Tchetgen:2012} is commonly used, which assumes that each unit in the neighbourhood is treated independently with probability $\alpha$ and that a unit's assignment is independent of its neighbours' assignment. This assumption rules out homophily---the tendency for units with similar characteristics to form ties---which is generally a strong and unrealistic assumption to make \parencite{Shalizi:2011}. In contrast, the estimators proposed by \textcite{Forastiere:2021} only use the observed neighbourhood treatments, and therefore no assumptions that explicitly rule out homophily are made (though the issue may still manifest as an unmeasured confounder if the unconfoundedness assumption does not hold for the given set of covariates). Both the IPW estimators and the estimators proposed by \textcite{Forastiere:2021} rely on being able to correctly model the joint propensity score.
\\

TMLEs are obtained by maximizing the likelihood of the outcomes defined on a structural equation model. Similar to the IPW estimators, TMLE typically involves a randomization assumption \parencite{VanDerLaan:2014} on the model where the conditional joint distribution of the treatment assignments factorizes into independent conditionals given the covariates for all units, and similarly for the conditional joint distribution of the outcomes given the covariates and the treatment assignments. In comparison, the unconfoundedness assumption in the method proposed by \textcite{Forastiere:2021} makes a weaker assumption where the outcome and treatment assignment of each unit is conditionally independent given only the covariates of that unit. The significance of these assumptions again circle back to the argument of disregarding homophily and/or other venues of confounding. It is notable that extensions of TMLE that allow for limited forms of homophily were later introduced \parencite{Ogburn:2017}.
\\

More recently, approaches that can be described as extensions of \textcite{Forastiere:2021}'s method have been proposed. \textcite{Jackson:2020} proposed estimators based on propensity score matching but which also explicitly account for homophily by modeling neighbourhood treatment assignments as an incomplete information game. \textcite{Sanchez:2021} questioned the justification of the unconfoundedness assumption with respect to the constructed propensity score (which may be high-dimensional and challenging to estimate accurately), and proposed a two-step method where a defined network propensity score is first estimated and then used as inverse weights to match units.

\subsubsection{Other contexts}

We briefly highlight other works in the literature that consider a slightly different setting of the causal inference problem in observational data under interference. The difference in settings makes it difficult to directly compare the proposed approaches to that of \textcite{Forastiere:2021}.
\\

A large body of the literature examine the inference problem under the assumption of partial interference where units are partitioned into groups with no spillover effects between groups. The focus on partial interference settings seems to be primarily due to momentum of earlier works \parencite[e.g.,][]{Sobel:2006,Hudgens:2008} that looked at causal inference in randomized studies with interference, in which group-randomization tends to be more practical. Examples of recent work that assume partial interference include the work by \textcite{Liu:2019}, \textcite{Barkley:2020}, and \textcite{Qu:2021}. IPW estimators are commonly used in the partial interference setting as they were originally introduced for grouped observational data \parencite{Tchetgen:2012}.
\\

A small number of works consider more specific and niche contexts. For example, \textcite{Toulis:2018} explore the problem of treatment entanglement (where treatment assignments are assumed to satisfy certain restrictions) and proposes a propensity score-based estimator. \textcite{Zigler:2021} focus on the problem of bipartite causal inference with interference (where the treatment is applied to one unit and the outcome is measured on another) and proposes a IPW estimator.
%Outside of the observational setting, there are many works that study causal inference in randomized studies with potential interference. These works generally examine study designs that allow for treatment effect estimation in the presence of interference under varying contexts \parencite[e.g.,][]{Saveski:2017,Jagadeesan:2020,Imai:2021,Doudchenko:2020}


\section{Potential bias of naive estimator when unconfoundedness holds}

In this section, we describe a simple example that illustrates the relevance of Theorem~2.A, Corollary~2 and Corollary~3 in the paper by \textcite{Forastiere:2021}. Specifically, we show how for a simple network under certain assumptions, an unbiased naive estimator for the treatment effect that assumes SUTVA may be biased depending on the exact treatment assignment mechanism.
\\

Consider some undirected network $G=(\calN,\calE)$ where every unit is paired (has an edge) with exactly one other unit. For simplicity, we index a unit by $i\in\bbN$ for the pair and $j\in\{1,2\}$ for the unit within a pair. Denote $Z_{ij}\in\{0,1\}$ as the treatment assignment of unit $j$ in pair $i$. Let the neighbourhood treatment~$G_{ij}$ be whether a unit's paired counterpart is treated. Therefore, $\calG_{ij}=\{0,1\}$ for all units in the network and $V_g=\calN$ for all $g\in\{0,1\}$. For convenience of notation, we drop the dependence on $V_g$ where applicable. Let $\bfX_{ij}=X_{ij}\in\{0,1\}$ be some covariate available for each unit, and assume that the covariates of the units in the network are generated independently with $\P(X_{ij}=1)=\P(X_{ij}=0)=\frac{1}{2}$. Other details, such as the space of outcomes $\calY$ and the size of $\calN$, are assumed but left unspecified due to being irrelevant for the discussion. Figure~\ref{fig:example} shows an example network.
\\

\begin{figure}[ht]
\centering
\begin{tikzpicture}[thick,main/.style={draw,circle},node distance={6.5em},minimum size={1cm}]
\node[main,align=center,label={[yshift=-0.5em]$X_{11}=1$}] (11) {$Z_{11}=1$\\$G_{11}=0$};
\node[main,align=center,label={[yshift=-7.5em]$X_{12}=0$}] (12) [below of=11] {$Z_{12}=0$\\$G_{12}=1$};
\draw[line width={0.5mm}] (11) -- (12);
\node[main,align=center,label={[yshift=-0.5em]$X_{21}=0$}] (21) [right of=11]{$Z_{21}=1$\\$G_{21}=1$};
\node[main,align=center,label={[yshift=-7.5em]$X_{22}=1$}] (22) [right of=12] {$Z_{22}=1$\\$G_{22}=1$};
\draw[line width={0.5mm}] (21) -- (22);
\node[] [right of=21] (d1) {\footnotesize$\bullet\bullet\bullet$};
\node[] [right of=22] (d2) {\footnotesize$\bullet\bullet\bullet$};
\node[main,align=center,label={[yshift=-0.5em]$X_{n1}=0$}] (n1) [right of=d1]{$Z_{n1}=0$\\$G_{n1}=0$};
\node[main,align=center,label={[yshift=-7.5em]$X_{n1}=0$}] (n2) [right of=d2] {$Z_{n2}=0$\\$G_{n2}=0$};
\draw[line width={0.5mm}] (n1) -- (n2);
\node[] [right of=n1] (d3) {\footnotesize$\bullet\bullet\bullet$};
\node[] [right of=n2] (d4) {\footnotesize$\bullet\bullet\bullet$};
\end{tikzpicture}
\caption{Example network of paired units with their individual treatment $Z_{ij}$, neighbourhood treatment $G_{ij}$, and covariate $X_{ij}$.}
\label{fig:example}
\end{figure}

We examine the network under two settings. In the first setting, suppose that the treatment assignment mechanism follows
\[
\P(Z_{ij}=1|X_{ij}) = \frac{1}{4} + \frac{1}{2}X_{ij} \;,
\]
i.e., the probability of being treated is greater when a unit has a 1-value for the covariate.
%the covariate $X_{ij}$ exactly determines the treatment status of a unit, i.e., $Z_{ij} = X_{ij}$.
Because $X_{ij}$ are generated independently, it follows that $Z_{ij}$ and $G_{ij}$ are conditionally independent given $X_{ij}$ in this setting (they are independent unconditionally regardless of $X_{ij}$). An example study corresponding to this setting may be one where the paired units correspond to a pair of friends from potentially different socioeconomic backgrounds $X_{ij}$, and it is of interest to determine whether being comfortable discussing financial matters ($Z_{ij}$) has an effect on some measure of their own financial management $Y_{ij}$.
\\

In the second setting, suppose that the treatment assignment follows
\[
\P(Z_{ij}=1|X_{i1},X_{i2}) = \frac{3}{4}\mathbbm{1}\left[X_{i1}=X_{i2}\right] + \frac{1}{4}\mathbbm{1}\left[X_{i1}\neq X_{i2}\right]
\]
where $\mathbbm{1}[\argdot]$ is the indicator function. This assignment corresponds to a type of homophily situation where the units in a pair are more likely to be treated if they share the same value of the covariate. Thus, $Z_{ij}$ and $G_{ij}$ are not conditionally independent given $X_{ij}$ in this setting as the probability of a unit being treated also depends on its counterpart. An example study corresponding to this setting may be one similar to the first but involving spouses rather than friends, where spouses coming from similar backgrounds may find it easier to discuss finances (at a more intimate level).
\\

In both settings, we further assume that Assumption~1 (no multiple versions of treatment), Assumption~2 (neighbourhood interference), and Assumption~3 (unconfoundedness) of \textcite{Forastiere:2021} hold. Hence, the assumptions of Corollary~1 are satisfied in the first setting, and the assumptions of Corollary~2 are satisfied in the second setting.

\subsection{Setting~1: conditionally independent individual and neighbourhood treatments}

In our first setting, the individual treatment $Z_{ij}$ and neighbourhood treatment $G_{ij}$ are conditionally independent given $X_{ij}$. By Corollary~1, an effect estimator that is unbiased under SUTVA will still be unbiased under the assumptions of our setting.
\\

The overall treatment effect $\tau$ in this setting is given by
\begin{align*}
%\tau(0) &= \mu(1,0) - \mu(0,0) \;, \\
%\tau(1) &= \mu(1,1) - \mu(0,1) \;, \\
\tau %&= \sum_{g\in\{0,1\}} \tau(g)\P(G_{ij}=g) \\
&= \sum_{g\in\{0,1\}} \left(\E\left[Y_{ij}(1,g)\right] - \E\left[Y_{ij}(0,g)\right]\right)\P(G_{ij}=g) \\
&= \frac{1}{2}\sum_{g,x\in\{0,1\}} \left(\E\left[Y_{ij}|Z_{ij}=1,G_{ij}=g,X_{ij}=x\right] - \E\left[Y_{ij}|Z_{ij}=0,G_{ij}=g,X_{ij}=x\right]\right)\P(X_{ij}=x) \\
&= \frac{1}{4}\sum_{g,x\in\{0,1\}} \left(\E\left[Y_{ij}|Z_{ij}=1,G_{ij}=g,X_{ij}=x\right] - \E\left[Y_{ij}|Z_{ij}=0,G_{ij}=g,X_{ij}=x\right]\right)
%&= \tau(0)\P(G_{ij}=0) + \tau(1)\P(G_{ij}=1) \\
%&= \frac{1}{2}\left(\mu(1,0) + \mu(1,1) - \mu(0,0) - \mu(0,1)\right) \;.
\end{align*}
where the second equality follows from Theorem~1 in the work by \textcite{Forastiere:2021}. The naive estimator $\tau_{X}^\text{obs}$ that assumes SUTVA estimates the quantity
\begin{align*}
\tau_{X}^\text{obs} &=
\sum_{x\in\{0,1\}}\left(\E\left[Y_{ij}|Z_{ij}=1,X_{ij}=x\right] - \E\left[Y_{ij}|Z_{ij}=0,X_{ij}=x\right]\right)\P(X_{ij}=x) \\
&= \frac{1}{2}\sum_{x,g\in\{0,1\}}\left(\E\left[Y_{ij}|Z_{ij}=1,X_{ij}=x,G_{ij}=g\right] - \E\left[Y_{ij}|Z_{ij}=0,X_{ij}=x,G_{ij}=g\right]\right)\P(G_{ij}=g) \\
&= \frac{1}{4}\sum_{x,g\in\{0,1\}}\left(\E\left[Y_{ij}|Z_{ij}=1,X_{ij}=x,G_{ij}=g\right] - \E\left[Y_{ij}|Z_{ij}=0,X_{ij}=x,G_{ij}=g\right]\right)
%&= \frac{1}{4}\sum_{x\in\{0,1\}}\left(\E\left[Y_{ij}|Z_{ij}=1,X_{ij}=x,G_{ij}=0\right] + \E\left[Y_{ij}|Z_{ij}=1,X_{ij}=x,G_{ij}=1\right]\right. \\
%&\quad - \left.\E\left[Y_{ij}|Z_{ij}=0,X_{ij}=x,G_{ij}=0\right] - \E\left[Y_{ij}|Z_{ij}=0,X_{ij}=x,G_{ij}=1\right]\right)
\end{align*}
where the second equality follows from the fact that $G_{ij}\condind X_{ij}, Z_{ij}$. It then follows from the above derivations that $\tau_{X}^\text{obs}-\tau = 0$.
\iffalse
and Assumptions~1 and 3 that
\begin{align*}
&\tau_{X}^\text{obs}-\tau \\
&= \tau_{X}^\text{obs} - \frac{1}{2}\left(\mu(1,0) + \mu(1,1) - \mu(0,0) - \mu(0,1)\right) \\
&= \tau_{X}^\text{obs} - \frac{1}{2}\sum_{x\in\{0,1\}}\left(\E\left[Y_{ij}|Z_{ij}=1,X_{ij}=x,G_{ij}=0\right] + \E\left[Y_{ij}|Z_{ij}=1,X_{ij}=x,G_{ij}=1\right]\right. \\
&\quad - \left.\E\left[Y_{ij}|Z_{ij}=0,X_{ij}=x,G_{ij}=0\right] - \E\left[Y_{ij}|Z_{ij}=0,X_{ij}=x,G_{ij}=1\right]\right)\P(X_{ij}=x) \\
&= 0 \;.
\end{align*}
\fi
Therefore, an unbiased estimator of the naive effect estimator is also unbiased for the treatment effect in this setting.

\subsection{Setting~2: correlated individual and neighbourhood treatments}

In our second setting, the covariate $X_{ij}$ alone is insufficient for the conditional independence of the individual treatment $Z_{ij}$ and neighbourhood treatment $G_{ij}$. By Corollary~2, an effect estimator that is unbiased under SUTVA will be biased under the assumptions of our setting.
\\

The overall treatment effect $\tau$ in this setting is the same as the one given in the first setting.
\iffalse
\begin{align*}
%\tau(0) &= \mu(1,0) - \mu(0,0) \;, \\
%\tau(1) &= \mu(1,1) - \mu(0,1) \;, \\
\tau &= \tau(0)\P(G_{ij}=0) + \tau(1)\P(G_{ij}=1) \\
&= \sum_{x_1,x_2\in\{0,1\}}\left(\tau(0)\P(G_{ij}=0|X_{i1}=x_1,X_{i2}=x_2) + \tau(1)\P(G_{ij}=1|X_{i1}=x_1,X_{i2}=x_2)\right)\P(X_{i1}=x_1,X_{i2}=x_2) \\
&= \frac{1}{4}\left(\tau(0)\left(\frac{1}{2}+\frac{3}{2}\right) + \tau(1)\left(\frac{3}{2}+\frac{1}{2}\right)\right) \\
&= \frac{1}{2}\left(\mu(1,0) + \mu(1,1) - \mu(0,0) - \mu(0,1)\right) \;.
\end{align*}
\fi
The naive estimator $\tau_{X}^\text{obs}$ that assumes SUTVA estimates the quantity
\begin{align*}
\tau_{X}^\text{obs} &= \sum_{x\in\{0,1\}}\left(\E\left[Y_{ij}|Z_{ij}=1,X_{ij}=x\right] - \E\left[Y_{ij}|Z_{ij}=0,X_{ij}=x\right]\right)\P(X_{ij}=x) \\
&= \frac{1}{2}\sum_{x,g\in\{0,1\}}\left(\E\left[Y_{ij}|Z_{ij}=1,X_{ij}=x,G_{ij}=g\right]\P(G_{ij}=g|Z_{ij}=1,X_{ij}=x)\right. \\
&\quad - \left.\E\left[Y_{ij}|Z_{ij}=0,X_{ij}=x,G_{ij}=g\right]\P(G_{ij}=g|Z_{ij}=0,X_{ij}=x)\right) \\
&= \frac{1}{2}\sum_{x,g\in\{0,1\}}\left(\E\left[Y_{ij}|Z_{ij}=1,X_{ij}=x,G_{ij}=g\right]\sum_{x'\in\{0,1\}}\P(G_{ij}=g|X_{ij}=x,X_{ik}=x')\P(X_{ik}=x'|Z_{ij}=1,X_{ij}=x)\right. \\
&\quad - \left.\E\left[Y_{ij}|Z_{ij}=0,X_{ij}=x,G_{ij}=g\right]\sum_{x'\in\{0,1\}}\P(G_{ij}=g|X_{ij}=x,X_{ik}=x')\P(X_{ik}=x'|Z_{ij}=0,X_{ij}=x)\right) \\
&= \frac{1}{2}\sum_{x,g\in\{0,1\}}\left(\E\left[Y_{ij}|Z_{ij}=1,X_{ij}=x,G_{ij}=g\right]\sum_{x'\in\{0,1\}}\P(G_{ij}=g|X_{ij}=x,X_{ik}=x')\P(Z_{ij}=1|X_{ij}=x,X_{ik}=x')\right. \\
&\quad - \left.\E\left[Y_{ij}|Z_{ij}=0,X_{ij}=x,G_{ij}=g\right]\sum_{x'\in\{0,1\}}\P(G_{ij}=g|X_{ij}=x,X_{ik}=x')\P(Z_{ij}=0|X_{ij}=x,X_{ik}=x')\right) \\
&= \frac{1}{2}\sum_{x\in\{0,1\}}\left(\left(2\left(\frac{3}{4}\right)^2+2\left(\frac{1}{4}\right)^2\right)\left(\E\left[Y_{ij}|Z_{ij}=1,X_{ij}=x,G_{ij}=1\right]-\E\left[Y_{ij}|Z_{ij}=0,X_{ij}=x,G_{ij}=0\right]\right) \right. \\
&\quad +\left. 4\cdot\frac{1}{4}\cdot\frac{3}{4}\left(\E\left[Y_{ij}|Z_{ij}=1,X_{ij}=x,G_{ij}=0\right]-\E\left[Y_{ij}|Z_{ij}=0,X_{ij}=x,G_{ij}=1\right]\right) \right) \\
&= \sum_{x\in\{0,1\}}\left(\frac{5}{8}\left(\E\left[Y_{ij}|Z_{ij}=1,X_{ij}=x,G_{ij}=1\right]-\E\left[Y_{ij}|Z_{ij}=0,X_{ij}=x,G_{ij}=0\right]\right) \right. \\
&\quad +\left. \frac{3}{8}\left(\E\left[Y_{ij}|Z_{ij}=1,X_{ij}=x,G_{ij}=0\right]-\E\left[Y_{ij}|Z_{ij}=0,X_{ij}=x,G_{ij}=1\right]\right) \right)
%&= \frac{1}{2}\left(2\left(\frac{3}{4}\right)^2+2\left(\frac{1}{4}\right)^2\right)\left(\mu(1,1) - \mu(0,0)\right) + \frac{1}{2}\cdot4\cdot\frac{1}{4}\cdot\frac{3}{4}\left(\mu(1,0) - \mu(0,1)\right) \\
%&= \frac{5}{8}\left(\mu(1,1) - \mu(0,0)\right) + \frac{3}{8}\left(\mu(1,0) - \mu(0,1)\right)
\end{align*}
where the third equality follows from the fact that $Z_{ij}\condind G_{ij}|X_{i1},X_{i2}$ and the fourth equality from Bayes' theorem manipulation (\todo Appendix?). The bias of an unbiased estimator for $\tau_{X}^\text{obs}$ is then
\[
\tau_{X}^\text{obs} - \tau = \frac{1}{8}\sum_{z,x\in\{0,1\}}\left(\E\left[Y_{ij}|Z_{ij}=z,G_{ij}=1,X_{ij}=x\right] - \E\left[Y_{ij}|Z_{ij}=z,G_{ij}=0,X_{ij}=x\right]\right)
%&= \frac{1}{8}\left(\mu(1,1) - \mu(1,0) - \mu(0,0) + \mu(0,1)\right) \;,
\]
which can be verified using the bias formula in Corollary~2 given by
\begin{align*}
\tau_{X}^\text{obs} - \tau &= \sum_{x\in\{0,1\}} \left(\left(\E\left[Y_{ij}|Z_{ij}=1,G_{ij}=1,X_{ij}=x\right] - \E\left[Y_{ij}|Z_{ij}=1,G_{ij}=0,X_{ij}=x\right]\right)\right. \\
&\qquad \left(\P(G_{ij}=1|Z_{ij}=1,X_{ij}=x)-\P(G_{ij}=1|X_{ij}=x)\right) \\
&\quad - \left(\E\left[Y_{ij}|Z_{ij}=0,G_{ij}=1,X_{ij}=x\right] - \E\left[Y_{ij}|Z_{ij}=0,G_{ij}=0,X_{ij}=x\right]\right) \\
&\qquad \left.\left(\P(G_{ij}=1|Z_{ij}=0,X_{ij}=x)-\P(G_{ij}=1|X_{ij}=x)\right)\right)\P(X_{ij}=x) \\
&= \frac{1}{2}\sum_{x,x'\in\{0,1\}} \left(\left(\E\left[Y_{ij}|Z_{ij}=1,G_{ij}=1,X_{ij}=x\right] - \E\left[Y_{ij}|Z_{ij}=1,G_{ij}=0,X_{ij}=x\right]\right)\right. \\
&\qquad \left(\P(G_{ij}=1|X_{ij}=x,X_{ik}=x')\P(Z_{ij}=1|X_{ij}=x,X_{ik}=x')-\P(G_{ij}=1|X_{ij}=x,X_{ik}=x')\P(X_{ik}=x')\right) \\
&\quad - \left(\E\left[Y_{ij}|Z_{ij}=0,G_{ij}=1,X_{ij}=x\right] - \E\left[Y_{ij}|Z_{ij}=0,G_{ij}=0,X_{ij}=x\right]\right) \\
&\qquad \left.\left(\P(G_{ij}=1|X_{ij}=x,X_{ik}=x')\P(Z_{ij}=0|X_{ij}=x,X_{ik}=x')-\P(G_{ij}=1|X_{ij}=x,X_{ik}=x')\P(X_{ik}=x')\right)\right) \\
&= \frac{1}{2}\sum_{x\in\{0,1\}}\left(\left(2\left(\frac{3}{4}\right)^2+2\left(\frac{1}{4}\right)^2 - 1\right)\left(\E\left[Y_{ij}|Z_{ij}=1,G_{ij}=1,X_{ij}=x\right] - \E\left[Y_{ij}|Z_{ij}=1,G_{ij}=0,X_{ij}=x\right]\right)\right. \\
&\quad - \left.\left(4\cdot\frac{1}{4}\cdot\frac{3}{4} - 1\right)\left(\E\left[Y_{ij}|Z_{ij}=0,G_{ij}=1,X_{ij}=x\right] - \E\left[Y_{ij}|Z_{ij}=0,G_{ij}=0,X_{ij}=x\right]\right)\right) \\
&= \frac{1}{8}\sum_{x,z\in\{0,1\}}\left(\E\left[Y_{ij}|Z_{ij}=z,G_{ij}=1,X_{ij}=x\right] - \E\left[Y_{ij}|Z_{ij}=z,G_{ij}=0,X_{ij}=x\right]\right)
\end{align*}
where the second equality follows from the same reasoning in the derivation of $\tau_X^\text{obs}$.


\section{Reproducing results of simulation study}

\todo In this section, we aim to (partially) reproduce the results of the simulation study conducted by \textcite{Forastiere:2021}. Note that we work with only the subset of the data that they use that is publicly accessible. The subset contains data for 6504 students (\todo: schools?) as opposed to the 16,410 students from 29 schools considered in their study.
\\

\begin{align*}
\text{logit}(P(Z_i=1) &= -3 + 3X_i^\text{game1} + 5X_i^\text{game2} \\
Y_i(z,g)|\Xind_i &\sim N\left(\mu(z,g,\Xind_i),1\right) \\
\mu(z,g,\Xind_i) &= 5 + 6\mathbbm{1}[\phi(1;\Xind_i)\geq 0.7] + 10z - 3z\mathbbm{1}[\phi(1;\Xind_i)\geq0.7] + \beta g \\
\tau(g) &= \mu(1,g,\Xind_i) - \mu(0,g,\Xind_i) = 10 - 3\mathbbm{1}[\phi(1;\Xind_i)\geq0.7] \qquad \forall g\in\calG \\
\tau &= \tau(g) \\
\delta(g;z) &= \mu(z,g,\Xind_i) - \mu(z,0,\Xind_i) = \beta g \\
\Delta(z) &= \delta\E[G_i] \qquad \forall z\in\{0,1\} \\
\mu(z,g,u) - \mu(z,0,u') &= 6(\mathbbm{1}[\phi(1;u)\geq 0.7]-\mathbbm{1}[\phi(1;u')\geq 0.7]) - 3z(\mathbbm{1}[\phi(1;u)\geq0.7] - \mathbbm{1}[\phi(1;u')\geq0.7]) + \beta g
\end{align*}

\todo: Complication: some larger degrees, difficult to compute $V_g$ for proportion $G$. For sum $G$, covariates must include degree for unconfoundedness to hold.


\section{Extending the simulation study}

\todo In this section, we consider a small extension to the simulation study.
\\


\section{Critical appraisal and concluding remarks}

\todo We conclude this report with a critical appraisal of the method proposed by \textcite{Forastiere:2021}.

\todo contributions, limitations

\todo unconfoundedness assumption? \textcite{Sanchez:2021}


\newpage


\begin{refcontext}[sorting=nyt]
\printbibliography
\end{refcontext}


\newpage

\appendix

\section{Additional derivations}

Under the assumptions of our second example setting,
\begin{align*}
\P(X_{ik}=x'|Z_{ij}=1,X_{ij}=x) &= \frac{\P(Z_{ij}=1|X_{ij}=x,X_{ik}=x')\P(X_{ik}=x')}{\P(Z_{ij}=1|X_{ij}=x)} \\
&= \frac{\P(Z_{ij}=1|X_{ij}=x,X_{ik}=x')\P(X_{ik}=x')}{\P(Z_{ij}=1|X_{ij}=X_{ik})P(X_{ij}=x) + \P(Z_{ij}=1|X_{ij}\neq X_{ik})P(X_{ij}=x')} \\
&= \left(\frac{\frac{1}{2}}{\frac{3}{4}\cdot\frac{1}{2}+\frac{1}{4}\cdot\frac{1}{2}}\right)\P(Z_{ij}=1|X_{ij}=x,X_{ik}=x') \\
&= \P(Z_{ij}=1|X_{ij}=x,X_{ik}=x')
\end{align*}
where the first equality follows from Bayes' theorem and the assumption that $X_{i1}\condind X_{i2}$.

\end{document}



The work by \textcite{Forastiere:2021} fits into the niche literature that looks at performing causal inference on observational network data in the presence of interference. \textcite{Forastiere:2021} formulate the network interference problem under the potential outcome framework (\todo cite), and propose a procedure to estimate causal treatment and spillover effects (as defined under their formulation) based on a joint propensity score that they define for network data. Their proposed propensity-adjusted estimators are unbiased under three assumptions, two of which form the Stable Unit Treatment on Neighbourhood Value Assumption (SUTNVA, a generalization of SUTVA that relaxes the no interference assumption to allow interference from directly connected nodes) and the third being an unconfoundedness assumption that says the treatment assignment mechanism is conditionally independent of the outcomes for some set of covariates. In addition, \textcite{Forastiere:2021} also derive the bias of SUTVA-assuming estimators when SUTVA does not hold or when the unconfoundedness assumption does not hold for the given set of covariates. The problem formulation, the proposed estimation procedure (based on a defined joint propensity score), and the derived bias of the naive estimator are the main contributions of \citeauthor{Forastiere:2021}.

\item
$\calN=\{1,2,3,4\}$, $\calE=\{(1,2),(3,4)\}$

\item
$\calY=\bbR$, $Z_i\in\{0,1\}$, $\calX=\{0,1\}$, $\calG_i=\{0,1\}$ for all $i$ (has treated friend), $V_g=\calN$ for all $g$

\item
If unconfoundedness assumption holds:
\begin{align*}
Y_i(z,g)|X_i &\sim N(\mu(z,g,X_i),1) \\
\mu(z,g,X_i) &= 6X_i + 3z + g
\end{align*}
Make deterministic:
\[
Y_i(z,g)|X_i = \mu(z,g,X_i) = 6X_i+3z+g
\]

\item
Corollary~1 holds:
\[
\textrm{logit}(P(Z_i=1)) = \log(0.5) + \log(4)X_i
\]
Make deterministic:

\item
Corollary~2 holds:
\[
\textrm{logit}(P(Z_i=1)) = \log(0.5) + \log(4)X_i + \log(2)\sum_{(i,j)\in\calE}X_j
\]


\item
Consider network where all units are in pairs.

$\calY=\bbR$, $Z_i\in\{0,1\}$, $\calX=\{0,1\}$, $\calG_i=\{0,1\}$ for all $i$ (has treated friend), $V_g=\calN$ for all $g$. $\P(X=1)=0.5$.

Corollary~1 setting: $Z_i=\mathbbm{1}(X_i=1)$ ($Z_i$ and $G_i$ entirely independent).

Corollary~2 setting: $Z_i=\sim X_i\otimes X_i'$ ($Z_i$ and $G_i$ not conditionally independent given $X_i$; only possible combinations are $(Z_i=1,G_i=1)$ and $(Z_i=0,G_i=0)$).

Show unbiasedness/biasedness of naive estimator (not accounting for spillover) based on averaging


\item
Setting 1:
\begin{align*}
\tau(1) &= \mu(1,1) - \mu(0,1) \\
\tau(0) &= \mu(1,0) - \mu(0,0) \\
\tau &= 0.5(\mu(1,0) + \mu(1,1) - \mu(0,0) - \mu(0,1)) \\
\end{align*}
\begin{align*}
\tau_{X^*}^\text{obs} &= 0.5(\E[Y|Z=1,X=0] - \E[Y|Z=0,X=0] + \E[Y|Z=1,X=1] - \E[Y|Z=0,X=1]) \\
&= \E[Y|Z=1] - \E[Y|Z=0] \\
&= \E[Y|Z=1,G=1]P(G=1|Z=1) + \E[Y|Z=1,G=0]P(G=0|Z=1) - \E[Y|Z=0,G=1]P(G=1|Z=0) - \E[Y|Z=0,G=0]P(G=0|Z=0) \\
&= 0.5(\E[Y|Z=1,G=1] + \E[Y|Z=1,G=0] - \E[Y|Z=0,G=1] - \E[Y|Z=0,G=0])
\end{align*}

\iffalse
\begin{align*}
\tau_{X}^\text{obs} &= \left(\E\left[Y_{ij}|Z_{ij}=1,X_{ij}=0\right] - \E\left[Y_{ij}|Z_{ij}=0,X_{ij}=0\right]\right)\P(X_{ij}=0) \\
&\quad + \left(\E\left[Y_{ij}|Z_{ij}=1,X_{ij}=1\right] - \E\left[Y_{ij}|Z_{ij}=0,X_{ij}=1\right]\right)\P(X_{ij}=1) \\
&= \E\left[Y_{ij}|Z_{ij}=1\right] - \E\left[Y_{ij}|Z_{ij}=0\right] \\
&= \left(\E\left[Y_{ij}|Z_{ij}=1,G_{ij}=0\right] - \E\left[Y_{ij}|Z_{ij}=0,G_{ij}=0\right]\right)\P(G_{ij}=0) \\
&\quad + \left(\E\left[Y_{ij}|Z_{ij}=1,G_{ij}=1\right] - \E\left[Y_{ij}|Z_{ij}=0,G_{ij}=1\right]\right)\P(G_{ij}=1) \\
&= 0.5\left(\mu(1,0) + \mu(1,1) - \mu(0,0) - \mu(0,1)\right)

&= \frac{1}{2}\left(\E\left[Y_{ij}|Z_{ij}=1,X_{ij}=0,G_{ij}=0\right]\P(G_{ij}=0) + \E\left[Y_{ij}|Z_{ij}=1,X_{ij}=0,G_{ij}=1\right]\P(G_{ij}=1)\right. \\
&\quad - \E\left[Y_{ij}|Z_{ij}=0,X_{ij}=0,G_{ij}=0\right]\P(G_{ij}=0) - \E\left[Y_{ij}|Z_{ij}=0,X_{ij}=0,G_{ij}=1\right]\P(G_{ij}=1) \\
&\quad + \E\left[Y_{ij}|Z_{ij}=1,X_{ij}=1,G_{ij}=0\right]\P(G_{ij}=0) + \E\left[Y_{ij}|Z_{ij}=1,X_{ij}=1,G_{ij}=1\right]\P(G_{ij}=1) \\
&\quad - \left.\E\left[Y_{ij}|Z_{ij}=0,X_{ij}=1,G_{ij}=0\right]\P(G_{ij}=0) - \E\left[Y_{ij}|Z_{ij}=0,X_{ij}=1,G_{ij}=1\right]\P(G_{ij}=1)\right) \\
\end{align*}
\fi

\begin{itemize}

\item
Setting 2:
\begin{align*}
\tau(1) &= \mu(1,1) \\
\tau(0) &= - \mu(0,0) \\
\tau &= 0.5(\mu(1,1) - \mu(0,0))
\end{align*}
\begin{align*}
\tau_{X^*}^\text{obs} &= 0.5(\E[Y|Z=1,X=0] - \E[Y|Z=0,X=0] + \E[Y|Z=1,X=1] - \E[Y|Z=0,X=1]) \\
&= \E[Y|Z=1] - \E[Y|Z=0] \\
&= \E[Y|Z=1,G=1]P(G=1|Z=1) + \E[Y|Z=1,G=0]P(G=0|Z=1) - \E[Y|Z=0,G=1]P(G=1|Z=0) - \E[Y|Z=0,G=0]P(G=0|Z=0) \\
&= \E[Y|Z=1,G=1] - \E[Y|Z=0,G=0]
\end{align*}
\begin{align*}
&\tau_{X^*}^\text{obs} \\
&= (\E[Y(1,1)|X=1]P(G=1|Z=1,X=1) - \E[Y(0,1)|X=1]P(G=1|Z=0,X=1))P(X=1) \\
& + (\E[Y(1,0)|X=1]P(G=0|Z=1,X=1) - \E[Y(0,0)|X=1]P(G=0|Z=0,X=1))P(X=1) \\
& + (\E[Y(1,1)|X=0]P(G=1|Z=1,X=0) - \E[Y(0,1)|X=0]P(G=1|Z=0,X=0))P(X=0) \\
& + (\E[Y(1,0)|X=0]P(G=0|Z=1,X=0) - \E[Y(0,0)|X=0]P(G=0|Z=0,X=0))P(X=0) \\
&= 0.5\E[Y(1,1)|X=1] - 0.5\E[Y(0,0)|X=1] + 0.5\E[Y(1,1)|X=0] - 0.5\E[Y(0,0)|X=0] \\
&= \E[Y(1,1)] - \E[Y(0,0)]
\end{align*}
\begin{align*}
&\tau_{X^*}^\text{obs} - \tau \\
&=(\E[Y|Z=1,G=1,X=1]-\E[Y|Z=1,G=0,X=1])(P(G=1|Z=1,X=1)-P(G=1|X=1))P(X=1) \\
&- (\E[Y|Z=0,G=1,X=1]-\E[Y|Z=0,G=0,X=1])(P(G=1|Z=0,X=1)-P(G=1|X=1))P(X=1) \\
&+ (\E[Y|Z=1,G=1,X=0]-\E[Y|Z=1,G=0,X=0])(P(G=1|Z=1,X=0)-P(G=1|X=0))P(X=0) \\
&- (\E[Y|Z=0,G=1,X=0]-\E[Y|Z=0,G=0,X=0])(P(G=1|Z=0,X=0)-P(G=1|X=0))P(X=0) \\
&= 0.25\E[Y|Z=1,G=1,X=1] - 0.25\E[Y|Z=0,G=0,X=1] + 0.25\E[Y|Z=1,G=1,X=0] - 0.25\E[Y|Z=0,G=0,X=0] \\
&= 0.5\E[Y|Z=1,G=1] - 0.5\E[Y|Z=0,G=0]
\end{align*}

\end{itemize}